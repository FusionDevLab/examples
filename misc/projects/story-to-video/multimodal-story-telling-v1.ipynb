{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b08354-812d-4ccf-a9bb-f217904c45b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdef9247-f884-4a58-b93f-d21a0eda424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b757fa-6ab1-4952-a616-4d43b4f51b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "# take openai key as input secret\n",
    "import getpass\n",
    "openai_key = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ec5fe5-3e8c-4bfb-8914-3c3b0ecace73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3716205-a09f-4d32-b7e3-edeb4b1886a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Read Your Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eae9690-fec7-4e73-94e8-07d5a93a5b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Files in data directory: ['0.txt', '1.txt', '2.txt', '3.txt']\n",
      "INFO:__main__:Read 4 parts from the story files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "data_dir = Path(os.getcwd()) / \"data\" / \"0\"\n",
    "parts = []\n",
    "files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]\n",
    "logger.info(f\"Files in data directory: {files}\")\n",
    "for f in files:\n",
    "    with open(data_dir / f, 'r', encoding='utf8') as file:\n",
    "        content = file.read()\n",
    "        parts.append(content)\n",
    "logger.info(f\"Read {len(parts)} parts from the story files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e105ad-cfb5-46e5-99d7-c1eb1a44ae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Arrival\\nIt was past 8:00 PM when Riya, Kabir, and Mehul entered the silent city of Bansipur.\\nA faint mist curled along the cracked roads, the streetlamps flickering as if unsure they wanted to stay lit.\\nThey had been driving for hours, lost after taking a wrong turn from the highway. Fuel gauge—dangerously low.\\nBansipur looked deserted, except for one building at the end of the main road:\\na bright, glowing sign that read “Mehta Super Mart – Always Open.”\\nRiya gave a nervous laugh.\\n“Creepy or not, we need snacks. And water. And… maybe a map.”\\nThey parked, the sound of their car engine echoing too loudly in the empty street.\\nThe sliding doors of the supermarket opened with a slow hiss, though no one stood behind the counter.\\nInside, the air was too cold for summer.\\nThe lights buzzed overhead, but the aisles were perfectly stocked—cereal boxes lined like soldiers, canned goods gleaming, fruits unnaturally shiny.\\nMehul called out, “Hello? Anyone here?”\\nOnly the sound of the automatic doors sighing shut behind them replied.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922a11c-0bde-48cb-abab-a640fe69dc1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scenes Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6fd44946-600c-4d9a-baea-03c3bd78ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a YouTube Shorts storyboard generator, cinematic scene visual prompt writer, and animation planner.\n",
    "\n",
    "I will give you a story.  \n",
    "Your task is to split it into coherent scenes for a short vertical video (9:16 aspect ratio) and ensure narration, visuals, and motion match **exactly**.\n",
    "\n",
    "---\n",
    "\n",
    "## Scene Planning Rules\n",
    "- **Sentence coverage:** Every sentence in the story **must appear** in the `narration_text` of some scene, in the same order as the story.  \n",
    "  - Do not skip or merge sentences in narration.  \n",
    "  - If a sentence is too short, merge it only with the immediately next one, but never drop it.\n",
    "- **Scene chunking:** End a scene whenever the location, main subject, or time changes. Never mix two locations or actions in one scene.\n",
    "- **Narration timing:** \n",
    "  - Target total video duration: {target_duration_sec} seconds\n",
    "  - Narration pace: {words_per_second} words/sec\n",
    "  - Each scene duration: 6–12 seconds\n",
    "- **Continuity:** Narration and visuals must represent the *same* moment in time.\n",
    "- **Perspective:** Visual prompts must always specify the exact camera POV (e.g., “point-of-view from driver’s seat,” “over-the-shoulder from Riya,” “low-angle looking up at supermarket sign”).\n",
    "- **Sound:** Narration output must also suggest background music or ambient sound effects that match the mood.\n",
    "- **Consistency:** Characters, props, vehicles, and environment must remain visually consistent across all scenes unless narration explicitly changes them.\n",
    "- **Aspect Ratio:** Always assume vertical 9:16 framing.\n",
    "\n",
    "---\n",
    "\n",
    "## Visual Prompt Requirements\n",
    "\n",
    "Each scene must have **staged prompts**, structured as an array called `visual_prompts`.  \n",
    "Each element in the array is an object with:\n",
    "\n",
    "- `stage_type`: one of **[\"base\", \"lighting\", \"style\", \"details\"]**  \n",
    "- `prompt`: description text  \n",
    "\n",
    "## Rules:\n",
    "1. **Stage 0 (base):**  \n",
    "   - Always defines **camera POV, subject, setting, and core action**.  \n",
    "   - Example: `\"Wide-angle from above, showing a car entering a misty, deserted city street at night.\"`\n",
    "\n",
    "2. **Stage 1 (lighting):**  \n",
    "   - Defines **time of day, weather, illumination, and atmosphere**.  \n",
    "   - Example: `\"Nighttime with flickering streetlamps and a faint mist.\"`\n",
    "\n",
    "3. **Stage 2 (details):**  \n",
    "   - Specifies **foreground, midground, background breakdown, textures, and extra props**.  \n",
    "   - For text on **signs, posters, or screens**, specify exactly as:  \n",
    "     `\"in-frame, clear, sharp, legible text displaying EXACTLY: 'YOUR TEXT HERE'.\"`  \n",
    "   - Example: `\"Foreground: cracked asphalt roads. Midground: car headlights reflecting on wet pavement. Background: mist swirling around tall buildings.\"`\n",
    "\n",
    "5. **If a stage is not needed, omit it.**  \n",
    "\n",
    "---\n",
    "\n",
    "## Example Structure\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"visual_prompts\": [\n",
    "    {{\n",
    "      \"stage_type\": \"base\",\n",
    "      \"prompt\": \"Wide-angle from above, showing a vintage car driving into a foggy, deserted city street at night.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"stage_type\": \"lighting\",\n",
    "      \"prompt\": \"Dim streetlights casting long shadows, soft mist illuminated by headlights, overall nighttime ambiance.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"stage_type\": \"details\",\n",
    "      \"prompt\": \"Foreground: cracked roads with reflections of neon lights. Midground: car headlights cutting through mist. Background: tall buildings fading into fog. A shop sign with in-frame, clear, sharp, legible text displaying EXACTLY: 'NIGHT CAFE'.\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "---\n",
    "\n",
    "## Animation Planning\n",
    "For each scene, pick the most suitable animation type based on the visual structure:\n",
    "\n",
    "- **Ken Burns:** Slow zoom/pan for close-up or still images.\n",
    "- **Parallax:** For layered depth (foreground/midground/background separation).\n",
    "- **Cinemagraph:** For subtle looping elements (flickering lights, mist, fire, rain).\n",
    "- **Dolly Zoom / Push In / Pan:** For dramatic tension or reveals.\n",
    "- **Static:** For moments meant to feel still and frozen.\n",
    "\n",
    "---\n",
    "\n",
    "## Output\n",
    "Return a valid JSON object with the following keys:\n",
    "\n",
    "- `profile` (object) with:\n",
    "  - `geographic_location`: {{ \"country\": str, \"specific_location\": str }}\n",
    "  - `time_period`: {{ \"era\": str, \"time_of_day\": str }}\n",
    "  - `weather`: {{ \"condition\": str, \"details\": str }}\n",
    "  - `ethnicity`: str\n",
    "  - `mood`: str\n",
    "  - `characters`: list of objects with:\n",
    "    - `name`: str (or \"Unnamed\" if not specified)\n",
    "    - `role`: str (hero, narrator, bystander, etc.)\n",
    "    - `visual_features`: str (clothing, hair, build, etc.)\n",
    "    - `psychological_features`: str (personality, emotions, motivations)\n",
    "\n",
    "- `scenes`: array of objects, each containing:\n",
    "  - `scene_index` (int): Scene number starting at 0.\n",
    "  - `narration_text` (str): Voiceover narration from the original story.  \n",
    "        ⚠ Must include every sentence of the story, in order, without omission.  \n",
    "  - `subtitle_text` (str): Short text (≤12 words) for on-screen subtitle.\n",
    "  - `visual_prompts` (array of objects):\n",
    "        [\n",
    "          {{\"stage_type\": \"base\", \"prompt\": \"...\"}},\n",
    "          {{\"stage_type\": \"lighting\", \"prompt\": \"...\"}},\n",
    "          {{\"stage_type\": \"details\", \"prompt\": \"...\"}}\n",
    "        ]\n",
    "  - `background_music` (str): Suggested BGM/ambient sound.\n",
    "  - `animation_type` (str): One of [\"Ken Burns\", \"Parallax\", \"Cinemagraph\", \"Dolly Zoom\", \"Static\"].\n",
    "  - `duration_sec` (int): Scene length in seconds.\n",
    "\n",
    "---\n",
    "\n",
    "Story:\n",
    "{story_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e074ac51-c8dc-4dc5-9c5e-69b73fa9a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "template = ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a47b86e-cc11-4bf1-93fa-48052323dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Literal\n",
    "\n",
    "\n",
    "class GeographicLocation(BaseModel):\n",
    "    country: Optional[str] = Field(None, description=\"Likely country where the story takes place\")\n",
    "    specific_location: Optional[str] = Field(None, description=\"Specific setting of the story\")\n",
    "\n",
    "\n",
    "class TimePeriod(BaseModel):\n",
    "    era: Optional[str] = Field(None, description=\"Era or historical context\")\n",
    "    time_of_day: Optional[str] = Field(None, description=\"Time of day in which the story occurs\")\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    condition: Optional[str] = Field(None, description=\"Weather condition (rainy, sunny, snowy)\")\n",
    "    details: Optional[str] = Field(None, description=\"Extra weather details (mist, storm, clear sky)\")\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str = Field(..., description=\"Character name or 'Unnamed'\")\n",
    "    role: Literal[\"hero\", \"narrator\", \"bystander\", \"antagonist\", \"supporting\"] = Field(\n",
    "        ..., description=\"Role in the story\"\n",
    "    )\n",
    "    visual_features: Optional[str] = Field(None, description=\"Appearance and clothing\")\n",
    "    psychological_features: Optional[str] = Field(None, description=\"Personality, emotions, motivations\")\n",
    "\n",
    "\n",
    "class Profile(BaseModel):\n",
    "    geographic_location: GeographicLocation\n",
    "    time_period: TimePeriod\n",
    "    weather: Weather\n",
    "    ethnicity: Optional[str] = Field(None, description=\"Ethnicity of main characters if implied\")\n",
    "    mood: Optional[str] = Field(None, description=\"Overall mood or tone of the scenes\")\n",
    "    characters: List[Character] = Field(default_factory=list, description=\"List of main characters\")\n",
    "\n",
    "\n",
    "class VisualPromptStage(BaseModel):\n",
    "    stage_type: Literal[\"base\", \"lighting\", \"details\"] = Field(\n",
    "        ..., description=\"Type of visual refinement stage\"\n",
    "    )\n",
    "    prompt: str = Field(..., description=\"Prompt text for this stage\")\n",
    "\n",
    "class Style(BaseModel):\n",
    "    style_description: str = Field(..., description=\"Cinematic noir, photorealistic, 35mm film still, deep contrast and grainy texture.\") \n",
    "\n",
    "class Scene(BaseModel):\n",
    "    scene_index: int = Field(..., description=\"Scene number starting at 0\")\n",
    "    narration_text: str = Field(..., description=\"Voiceover narration from the original story\")\n",
    "    subtitle_text: str = Field(..., max_length=50, description=\"Short subtitle (≤12 words)\")\n",
    "    visual_prompts: List[VisualPromptStage] = Field(\n",
    "        ..., description=\"Array of visual prompts for staged image generation\"\n",
    "    )\n",
    "    background_music: str = Field(..., description=\"Suggested BGM/ambient sound\")\n",
    "    animation_type: Literal[\"Ken Burns\", \"Parallax\", \"Cinemagraph\", \"Dolly Zoom\", \"Static\"] = Field(\n",
    "        ..., description=\"Animation type\"\n",
    "    )\n",
    "    duration_sec: int = Field(..., ge=3, le=15, description=\"Scene duration in seconds (3–15)\")\n",
    "\n",
    "\n",
    "class StoryBoard(BaseModel):\n",
    "    profile: Profile\n",
    "    style: Style\n",
    "    scenes: List[Scene]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9abba26b-c33d-4cbe-bfc5-f906a74d6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    openai_api_key=openai_key,\n",
    ")\n",
    "\n",
    "llm = llm.with_structured_output(StoryBoard)  # Enable structured output for Scenes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d7356eff-9357-4b79-b46d-402344e8ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0e06a2cc-8986-49f9-81a2-2d3ab524cd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"story_text\": \"\\n\\n\".join(parts),\n",
    "    \"target_duration_sec\": 60,\n",
    "    \"words_per_second\": 3\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d21a1a52-cc08-4d4f-9d87-a7cfb890cbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68f8c07d-549f-4eaa-8c25-3ac30cffef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile(geographic_location=GeographicLocation(country='India', specific_location='Bansipur'), time_period=TimePeriod(era='modern', time_of_day='night'), weather=Weather(condition='misty', details='faint mist curling along roads'), ethnicity='South Asian', mood='eerie and suspenseful', characters=[Character(name='Riya', role='hero', visual_features='long black hair, wearing a denim jacket and jeans', psychological_features='nervous but determined'), Character(name='Kabir', role='supporting', visual_features='short hair, wearing a hoodie and cargo pants', psychological_features='cautious and observant'), Character(name='Mehul', role='supporting', visual_features='curly hair, wearing a t-shirt and backpack', psychological_features='curious and skeptical')])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5a0f18b3-ea32-4e54-99a8-68a777822ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Style(style_description='Cinematic noir, photorealistic, 35mm film still, deep contrast and grainy texture.')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "42cca304-20d6-4ea5-8aca-9b673c4117e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scene(scene_index=0, narration_text='It was past 8:00 PM when Riya, Kabir, and Mehul entered the silent city of Bansipur. A faint mist curled along the cracked roads, the streetlamps flickering as if unsure they wanted to stay lit.', subtitle_text='Entering Bansipur at night.', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Wide-angle from above, showing a car entering a misty, deserted city street at night.'), VisualPromptStage(stage_type='lighting', prompt='Nighttime with flickering streetlamps and a faint mist.'), VisualPromptStage(stage_type='details', prompt='Foreground: cracked asphalt roads. Midground: car headlights reflecting on wet pavement. Background: mist swirling around tall buildings.')], background_music='Eerie ambient tones with distant echoes.', animation_type='Parallax', duration_sec=10)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.scenes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f7fa9-172d-4dae-93e8-681224db195a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scene Profile (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e1cdce6-c6df-4f8e-9fa0-9eb72d9475f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def to_profile_tab(profile: Profile) -> str:\n",
    "    rows = [\n",
    "        [\"Geographic Location\", f\"{profile.geographic_location.country or ''}, {profile.geographic_location.specific_location or ''}\"],\n",
    "        [\"Time Period\", f\"Era: {profile.time_period.era or ''}, Time: {profile.time_period.time_of_day or ''}\"],\n",
    "        [\"Weather\", f\"{profile.weather.condition or ''} ({profile.weather.details or ''})\"],\n",
    "        [\"Ethnicity\", profile.ethnicity or \"\"],\n",
    "        [\"Mood\", profile.mood or \"\"],\n",
    "    ]\n",
    "    \n",
    "    # Add characters as a sub-table\n",
    "    char_rows = []\n",
    "    for c in profile.characters:\n",
    "        char_rows.append([\n",
    "            c.name,\n",
    "            c.role,\n",
    "            c.visual_features or \"\",\n",
    "            c.psychological_features or \"\"\n",
    "        ])\n",
    "    \n",
    "    table_str = tabulate(rows, headers=[\"Attribute\", \"Value\"], tablefmt=\"grid\")\n",
    "    \n",
    "    if char_rows:\n",
    "        char_table = tabulate(\n",
    "            char_rows, \n",
    "            headers=[\"Name\", \"Role\", \"Visual Features\", \"Psychological Features\"], \n",
    "            tablefmt=\"grid\"\n",
    "        )\n",
    "        table_str += \"\\n\\nCharacters:\\n\" + char_table\n",
    "    \n",
    "    return table_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdd5ab20-a0a8-4dbf-9713-21f869fb5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_str = to_profile_tab(result.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d12d0c56-b46d-4171-9a70-32a6cbae803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------------------------------+\n",
      "| Attribute           | Value                                      |\n",
      "+=====================+============================================+\n",
      "| Geographic Location | India, Bansipur                            |\n",
      "+---------------------+--------------------------------------------+\n",
      "| Time Period         | Era: modern, Time: night                   |\n",
      "+---------------------+--------------------------------------------+\n",
      "| Weather             | misty (faint mist, flickering streetlamps) |\n",
      "+---------------------+--------------------------------------------+\n",
      "| Ethnicity           | South Asian                                |\n",
      "+---------------------+--------------------------------------------+\n",
      "| Mood                | eerie and suspenseful                      |\n",
      "+---------------------+--------------------------------------------+\n",
      "\n",
      "Characters:\n",
      "+--------+--------+-----------------------------------------+--------------------------+\n",
      "| Name   | Role   | Visual Features                         | Psychological Features   |\n",
      "+========+========+=========================================+==========================+\n",
      "| Riya   | hero   | long black hair, wearing a denim jacket | nervous but determined   |\n",
      "+--------+--------+-----------------------------------------+--------------------------+\n",
      "| Kabir  | hero   | short hair, wearing a hoodie            | curious and cautious     |\n",
      "+--------+--------+-----------------------------------------+--------------------------+\n",
      "| Mehul  | hero   | tall, wearing glasses and a backpack    | analytical and skeptical |\n",
      "+--------+--------+-----------------------------------------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(profile_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c02943-36e2-444d-af22-b3e709f9f215",
   "metadata": {},
   "source": [
    "# Stage Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb7791c6-99a2-48ea-ba7c-8cb7affd5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from pathlib import Path\n",
    "\n",
    "id = str(uuid4())\n",
    "\n",
    "stage_dir = Path(os.getcwd()) / \"stage\" / id\n",
    "stage_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "517bd3cb-7342-450b-8e13-16fc4933f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = stage_dir / \"images\"\n",
    "raw_images_dir = images_dir / \"raw\"\n",
    "raw_images_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee51fd9d-b46e-4200-ab44-5bf01c4ab896",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_images_dir = images_dir / \"clean\"\n",
    "clean_images_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80cb8b67-50d0-41df-be40-e9075fddd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = stage_dir / \"audios\"\n",
    "audio_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bd2c98c-c5c8-4bd5-90e8-f128a7228b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = stage_dir / \"videos\"\n",
    "video_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293da449-3053-4271-97c4-95b93bf5503c",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7fb40a61-acad-4b9f-9ac8-a21e87246e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_index=13 narration_text='They looked exactly like Riya, Kabir, and Mehul—but their faces were twisted, rotting, their eyes black pits. The next flicker of light went out completely. In the darkness, the footsteps came closer. The last thing anyone heard was the supermarket doors hissing open upstairs… …with no one coming out.' subtitle_text='The final horror.' visual_prompts=[VisualPromptStage(stage_type='base', prompt=\"Close-up of the ghostly figures' faces, twisted and rotting.\"), VisualPromptStage(stage_type='lighting', prompt='Flickering lights casting eerie shadows.'), VisualPromptStage(stage_type='details', prompt='Foreground: ghostly faces. Midground: flickering lights. Background: shadowy walls.')] background_music='Creepy ambient tones with a rising tension.' animation_type='Cinemagraph' duration_sec=12\n"
     ]
    }
   ],
   "source": [
    "current = result.scenes[13]\n",
    "print(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ebf5d1b8-6aaa-4e37-9181-17411f024eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close-up of the ghostly figures' faces, twisted and rotting.\n",
      "Flickering lights casting eerie shadows.\n",
      "Foreground: ghostly faces. Midground: flickering lights. Background: shadowy walls.\n",
      "\n",
      "Cinematic noir, photorealistic, 35mm film still, deep contrast and grainy texture.\n"
     ]
    }
   ],
   "source": [
    "whole = '\\n'.join([ prompt.prompt for prompt in current.visual_prompts])\n",
    "whole = f\"{whole}\\n\\n{result.style.style_description}\"\n",
    "print(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "300f1285-b2f3-48ce-9871-3ad4f8a82661",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = \"http://18.207.254.53:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "250514e9-136d-451a-a01c-246dc71cb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "_NEGATIVE_PROMPT = \"\"\"\n",
    "    blurry, low quality, \n",
    "    low resolution, bad anatomy, bad hands, \n",
    "    missing fingers, extra digit, fewer digits, \n",
    "    cropped, worst quality, low quality, \n",
    "    normal quality, jpeg artifacts, signature, watermark, username, blurry,\n",
    "    cartoon, anime, illustration, comic, flat shading\n",
    "\"\"\"\n",
    "\n",
    "_DEFAULT_PARAMS = {\n",
    "    'guidance_scale': 7.5,\n",
    "    'strength': 0.45,\n",
    "    'orientation': 'portrait'\n",
    "}\n",
    "\n",
    "def call(text: str, image_path: str = None, params: dict = _DEFAULT_PARAMS):\n",
    "    path = \"/sm/txt2img\"\n",
    "    data = {\n",
    "        'prompt': text,\n",
    "        'negative_prompt': _NEGATIVE_PROMPT,\n",
    "        **params\n",
    "    }\n",
    "    if image_path:\n",
    "        path = \"/sm/img2img\"\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            data[\"image\"] = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    endpoint = f\"{api}{path}\"\n",
    "\n",
    "    response = requests.post(endpoint, \n",
    "                             data=json.dumps(data), \n",
    "                             headers={'Content-Type': 'application/json'},\n",
    "                             timeout=3000)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Request failed: {response.status_code} {response.text}\")\n",
    "    else:\n",
    "        img = json.loads(response.content.decode('utf-8'))\n",
    "        image_bytes = base64.b64decode(img['image_base64'])\n",
    "        return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0deb9a08-ff61-4652-bda8-8d107cc9059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def generate_raw_scene(idx: int, dir: str):\n",
    "    style = result.style\n",
    "    scene = result.scenes[idx]\n",
    "    images_dir = dir / str(idx)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    style_prompt = VisualPromptStage(stage_type=\"details\", prompt=style.style_description)\n",
    "    for i, prompt in enumerate([*scene.visual_prompts, style_prompt]):\n",
    "        logger.info(f\"Generating image for scene {idx}, prompt {i}: {prompt.prompt}\")\n",
    "        if i == 0:\n",
    "            img = call(text=prompt.prompt)\n",
    "        else:\n",
    "            prev_img_path = images_dir / f\"{i-1}.png\"\n",
    "            img = call(text=prompt.prompt, image_path=prev_img_path)\n",
    "        \n",
    "        output_path = images_dir / f\"{i}.png\"\n",
    "    \n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(img)\n",
    "        \n",
    "        if i == len(scene.visual_prompts) - 1:\n",
    "            output_path = images_dir / f\"final.png\"\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(img)\n",
    "\n",
    "    logger.info(f\"completed scene generation for scene - {idx}\")\n",
    "        \n",
    "def generate_raw_combined_scene(idx: int, dir: str):\n",
    "    style = result.style\n",
    "    scene = result.scenes[idx]\n",
    "    images_dir = dir / str(idx)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    whole = '\\n'.join([ prompt.prompt for prompt in scene.visual_prompts])\n",
    "    whole = f\"{whole}\\n\\n{style.style_description}\"\n",
    "    \n",
    "    img = call(text=whole)\n",
    "    output_path = images_dir / \"final.png\"\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(img)\n",
    "    \n",
    "    logger.info(f\"completed scene generation for scene - {idx}\")\n",
    "\n",
    "def generate_raw_combined_scene_with_past_reference(idx: int, dir: str):\n",
    "    style = result.style\n",
    "    scene = result.scenes[idx]\n",
    "    images_dir = dir / str(idx)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    past_image = None\n",
    "    if idx > 0:\n",
    "        past_image_path = dir / str(idx - 1) / \"final.png\"\n",
    "        if past_image_path.exists():\n",
    "            past_image = past_image_path\n",
    "    \n",
    "    whole = '\\n'.join([ prompt.prompt for prompt in scene.visual_prompts])\n",
    "    whole = f\"{whole}\\n\\n{style.style_description}\"\n",
    "\n",
    "    if past_image:\n",
    "        img = call(text=whole, image_path=str(past_image), params = { **__DEFAULT_PARAMS, 'strength': 0.5 })\n",
    "    else:\n",
    "        # If no past image, generate from scratch\n",
    "        img = call(text=whole)\n",
    "    output_path = images_dir / \"final.png\"\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(img)\n",
    "    \n",
    "    logger.info(f\"completed scene generation for scene - {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6b6433ee-4a2c-4cf5-986e-9528290baf89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:completed scene generation for scene - 0\n",
      "INFO:__main__:completed scene generation for scene - 1\n",
      "INFO:__main__:completed scene generation for scene - 2\n",
      "INFO:__main__:completed scene generation for scene - 3\n",
      "INFO:__main__:completed scene generation for scene - 4\n",
      "INFO:__main__:completed scene generation for scene - 5\n",
      "INFO:__main__:completed scene generation for scene - 6\n",
      "INFO:__main__:completed scene generation for scene - 7\n",
      "INFO:__main__:completed scene generation for scene - 8\n",
      "INFO:__main__:completed scene generation for scene - 9\n",
      "INFO:__main__:completed scene generation for scene - 10\n",
      "INFO:__main__:completed scene generation for scene - 11\n",
      "INFO:__main__:completed scene generation for scene - 12\n",
      "INFO:__main__:completed scene generation for scene - 13\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for idx, scene in enumerate(result.scenes):\n",
    "    generate_raw_combined_scene(idx, raw_images_dir)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2f012-4fea-49e9-9624-0e698dda3c59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Image Upscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a91822e5-f315-4c6d-89de-a0d62639bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "\n",
    "def upscale(image_path: str = None, params: dict = {}):\n",
    "    path = \"/upscale/latent/v2\"\n",
    "    data = {\n",
    "        **params\n",
    "    }\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        data[\"image\"] = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    endpoint = f\"{api}{path}\"\n",
    "\n",
    "    response = requests.post(endpoint, \n",
    "                             data=json.dumps(data), \n",
    "                             headers={'Content-Type': 'application/json'},\n",
    "                             timeout=3000)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Request failed: {response.status_code} {response.text}\")\n",
    "    else:\n",
    "        img = json.loads(response.content.decode('utf-8'))\n",
    "        image_bytes = base64.b64decode(img['image_base64'])\n",
    "        return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1592b2b1-30e0-44cb-b0e7-4a938c1fd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def upscale_raw_scene(idx: int, input_dir: str, output_dir: str):\n",
    "    images_dir = output_dir\n",
    "    source_img_path = input_dir / f\"{idx}\" / \"final.png\"\n",
    "    image_bytes = upscale(source_img_path)\n",
    "    output_path = images_dir / f\"{idx}.png\"\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "90f4ce47-0f6a-43c5-a54e-7cb805b2ae78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPConnectionPool(host='18.207.254.53', port=8000): Read timed out. (read timeout=3000)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1411\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:324\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:285\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[31mTimeoutError\u001b[39m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: HTTPConnectionPool(host='18.207.254.53', port=8000): Read timed out. (read timeout=3000)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[136]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, scene \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(result.scenes):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mupscale_raw_scene\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_images_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_images_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     time.sleep(\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[134]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mupscale_raw_scene\u001b[39m\u001b[34m(idx, input_dir, output_dir)\u001b[39m\n\u001b[32m      4\u001b[39m images_dir = output_dir\n\u001b[32m      5\u001b[39m source_img_path = input_dir / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mfinal.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m image_bytes = \u001b[43mupscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_img_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m output_path = images_dir / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[133]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mupscale\u001b[39m\u001b[34m(image_path, params)\u001b[39m\n\u001b[32m     12\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m] = base64.b64encode(f.read()).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m endpoint = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequest failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:713\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
      "\u001b[31mReadTimeout\u001b[39m: HTTPConnectionPool(host='18.207.254.53', port=8000): Read timed out. (read timeout=3000)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for idx, scene in enumerate(result.scenes):\n",
    "    upscale_raw_scene(idx, raw_images_dir, clean_images_dir)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43b65b-cba8-422d-bc20-b91760cd5a27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b9753b0-9354-4222-bce9-7e3c59413268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_tts(text, filename):\n",
    "    \"\"\"Generate narration audio from text using OpenAI TTS.\"\"\"\n",
    "    speech = client.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"alloy\",\n",
    "        input=text\n",
    "    )\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(speech.read())\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b873e98-88b4-4612-b392-21803f550c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "audio_dir = stage_dir / \"audios\"\n",
    "audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "\n",
    "for idx, scene in enumerate(result.scenes):\n",
    "    output_path = images_dir / f\"scene_{idx}.png\"\n",
    "    generate_tts(scene.narration_text, output_path)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2bc71e-2123-4d93-8742-f862492e8e5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Generate Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c0217-a9e3-4fc4-9a80-e19ff6a69ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672c167-a76e-4378-9138-23cdea2fba60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7001438b-de3a-42d7-aac5-de7ebfc2cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def tts_generate(text, filename):\n",
    "    \"\"\"Generate narration audio from text using OpenAI TTS.\"\"\"\n",
    "    speech = client.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"alloy\",\n",
    "        input=text\n",
    "    )\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(speech.read())\n",
    "    return filename\n",
    "\n",
    "def image_generate(prompt, filename):\n",
    "    \"\"\"Generate image using OpenAI image API.\"\"\"\n",
    "    img = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1536\"\n",
    "    )\n",
    "    print(f\"Generated image for prompt: {prompt}\")\n",
    "    image_base64 = img.data[0].b64_json\n",
    "\n",
    "    # Step 3 — Decode base64 → bytes\n",
    "    image_bytes = base64.b64decode(image_base64)\n",
    "    \n",
    "    # Step 4 — Open with Pillow\n",
    "    img = Image.open(BytesIO(image_bytes))\n",
    "    \n",
    "    # Step 5 — Resize to YouTube Shorts-friendly 1080x1920\n",
    "    img = img.resize((1080, 1920), Image.LANCZOS)\n",
    "    \n",
    "    # Step 6 — Save\n",
    "    img.save(filename)\n",
    "    print(f\"Image saved as {filename}\")\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2930abc7-a113-4d9b-a92a-6f35141aad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def create_video_with_ffmpeg(image_path, audio_path, output_path, duration):\n",
    "    # Create a video from a single image + audio, loop image for duration\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",\n",
    "        \"-loop\", \"1\",\n",
    "        \"-i\", image_path,\n",
    "        \"-i\", audio_path,\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-tune\", \"stillimage\",\n",
    "        \"-c:a\", \"aac\",\n",
    "        \"-b:a\", \"192k\",\n",
    "        \"-pix_fmt\", \"yuv420p\",\n",
    "        \"-shortest\",\n",
    "        output_path\n",
    "    ]\n",
    "    subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75f19286-0423-4694-9b5c-23da979801ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image for prompt: A wide-angle shot of a deserted city street at night. The scene is ultra-realistic with a moody, noir style. Streetlamps cast flickering, dim light over cracked roads. A faint mist swirls, creating an eerie atmosphere. The camera captures the scene from a low angle, emphasizing the desolation. Colors are muted with a cold blue tint, enhancing the chilling mood. Textures of cracked asphalt and swirling mist are prominent.\n",
      "Image saved as scene0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image for prompt: A medium shot of a car parked on an empty street, with a glowing neon sign of 'Mehta Super Mart' in the background. The scene is depicted in a cinematic, neo-noir style with vibrant neon colors contrasting against the dark surroundings. The camera captures the scene from a slightly elevated angle, focusing on the car and the sign. The neon glow casts colorful reflections on the wet pavement, adding texture and depth.\n",
      "Image saved as scene1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image for prompt: An ultra-realistic, wide-angle shot of the supermarket interior. The scene is brightly lit with a sterile, fluorescent glow. The camera captures the aisles from a low angle, emphasizing the perfectly stocked shelves. Colors are vibrant but slightly surreal, with a focus on the shiny, unnatural appearance of the products. The buzzing of the lights adds an unsettling atmosphere.\n",
      "Image saved as scene2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image for prompt: A narrow staircase descending into darkness, lit by a single, flickering bulb. The scene is captured in a film noir style with deep shadows and high contrast. The camera takes a close-up shot of the sign and the staircase, emphasizing the mystery and foreboding atmosphere. The colors are muted, with a focus on the interplay of light and shadow.\n",
      "Image saved as scene3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image for prompt: A surreal, Escher-like staircase scene with repeating elements. The camera captures the scene from a wide-angle, slightly tilted perspective, emphasizing the disorienting, infinite nature of the staircases. The lighting is dim, with a single bulb casting long shadows. The colors are dark and gritty, enhancing the sense of confusion and unease.\n",
      "Image saved as scene4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image for prompt: A close-up shot of a dark red smear on a wall, with a flickering bulb above. The scene is captured in a horror style with high contrast and deep shadows. The camera focuses on the texture of the smear, with the bulb casting an eerie glow. The colors are dark and ominous, with a focus on the red smear and the shadows it casts.\n",
      "Image saved as scene5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image for prompt: A dark, atmospheric shot of a staircase with faint, approaching footsteps. The scene is captured in a suspenseful, thriller style with minimal lighting. The camera takes a low-angle shot, focusing on the staircase and the shadows. The colors are muted, with a focus on the interplay of light and shadow. The atmosphere is tense, with a sense of impending danger.\n",
      "Image saved as scene6.png\n"
     ]
    }
   ],
   "source": [
    "scene_videos = []\n",
    "\n",
    "for idx, scene in enumerate(result.scenes):\n",
    "    audio_file = f\"scene{idx}.mp3\"\n",
    "    image_file = f\"scene{idx}.png\"\n",
    "    video_file = f\"scene{idx}.mp4\"\n",
    "\n",
    "    # Generate assets\n",
    "    tts_generate(scene.narration_text, audio_file)\n",
    "    image_generate(scene.visual_prompt, image_file)\n",
    "\n",
    "    # Estimate duration from narration speed (~3 words/sec)\n",
    "    words = len(scene.narration_text.split())\n",
    "    duration = round(words / 3.0, 1)\n",
    "\n",
    "    # Combine into scene video\n",
    "    create_video_with_ffmpeg(image_file, audio_file, video_file, duration)\n",
    "    scene_videos.append(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ff26e5-95c5-464d-b9a4-6d3de53360a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_videos = [\n",
    "    \"scene0.mp4\",\n",
    "    \"scene1.mp4\",\n",
    "    \"scene2.mp4\",\n",
    "    \"scene3.mp4\",\n",
    "    \"scene4.mp4\",\n",
    "    \"scene5.mp4\",\n",
    "    \"scene6.mp4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78442e86-74b2-4a71-a80f-fe537786c72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-f', 'concat', '-safe', '0', '-i', 'scenes.txt', '-c', 'copy', 'story_1.mp4'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"scenes.txt\", \"w\") as f:\n",
    "    for video in scene_videos:\n",
    "        f.write(f\"file '{video}'\\n\")\n",
    "\n",
    "import subprocess\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", \"scenes.txt\",\n",
    "    \"-c\", \"copy\", \"story_1.mp4\"\n",
    "], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e141886-1052-40e1-b7f0-ed277300b67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb729fc8-b1df-4727-92ea-e5f3f2cd204b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
