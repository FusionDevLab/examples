{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b08354-812d-4ccf-a9bb-f217904c45b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdef9247-f884-4a58-b93f-d21a0eda424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b757fa-6ab1-4952-a616-4d43b4f51b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "# take openai key as input secret\n",
    "import getpass\n",
    "openai_key = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ec5fe5-3e8c-4bfb-8914-3c3b0ecace73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3716205-a09f-4d32-b7e3-edeb4b1886a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Read Your Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0eae9690-fec7-4e73-94e8-07d5a93a5b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Files in data directory: ['0.txt', '1.txt', '2.txt', '3.txt']\n",
      "INFO:__main__:Read 4 parts from the story files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "data_dir = Path(os.getcwd()) / \"data\" / \"0\"\n",
    "parts = []\n",
    "files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]\n",
    "logger.info(f\"Files in data directory: {files}\")\n",
    "for f in files:\n",
    "    with open(data_dir / f, 'r', encoding='utf8') as file:\n",
    "        content = file.read()\n",
    "        parts.append(content)\n",
    "logger.info(f\"Read {len(parts)} parts from the story files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84e105ad-cfb5-46e5-99d7-c1eb1a44ae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Arrival\\nIt was past 8:00 PM when Riya, Kabir, and Mehul entered the silent city of Bansipur.\\nA faint mist curled along the cracked roads, the streetlamps flickering as if unsure they wanted to stay lit.\\nThey had been driving for hours, lost after taking a wrong turn from the highway. Fuel gauge—dangerously low.\\nBansipur looked deserted, except for one building at the end of the main road:\\na bright, glowing sign that read “Mehta Super Mart – Always Open.”\\nRiya gave a nervous laugh.\\n“Creepy or not, we need snacks. And water. And… maybe a map.”\\nThey parked, the sound of their car engine echoing too loudly in the empty street.\\nThe sliding doors of the supermarket opened with a slow hiss, though no one stood behind the counter.\\nInside, the air was too cold for summer.\\nThe lights buzzed overhead, but the aisles were perfectly stocked—cereal boxes lined like soldiers, canned goods gleaming, fruits unnaturally shiny.\\nMehul called out, “Hello? Anyone here?”\\nOnly the sound of the automatic doors sighing shut behind them replied.\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922a11c-0bde-48cb-abab-a640fe69dc1f",
   "metadata": {},
   "source": [
    "# Scenes Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd44946-600c-4d9a-baea-03c3bd78ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a YouTube Shorts storyboard generator and animation planner.\n",
    "\n",
    "I will give you a story. Split it into coherent scenes for a short vertical video (9:16). Ensure narration, visuals, and motion match exactly.\n",
    "\n",
    "IMPORTANT: EVERY sentence from the story MUST appear in narration_text of a scene.\n",
    "Do not skip, merge, or truncate sentences. Ignore duration or scene count if it conflicts with this.\n",
    "\n",
    "## Style\n",
    "- The `style` field is a **single descriptive string** capturing the cinematic style for the entire video.\n",
    "- Include lens type, film format, lighting, mood, visual tone, and any director/genre references.\n",
    "- This string will guide SDXL’s rendering across all scenes.\n",
    "\n",
    "---\n",
    "\n",
    "## Scene Rules\n",
    "- Chunking: Default = one scene per 2-3 sentences. Also merge if sentence ≤10 words or incomplete. Split if multiple locations/actions.\n",
    "- Continuity: Narration and visuals represent the same moment.\n",
    "- Perspective: Specify exact camera POV.\n",
    "- Sound: Suggest background music or ambient sound per scene.\n",
    "- Consistency: Keep characters/props/environment consistent unless narration changes.\n",
    "- Aspect Ratio: Vertical 9:16.\n",
    "- Choose values according to **how similar the current scene is to the previous**.\n",
    "- Do not truncate narration to satisfy strength.\n",
    "\n",
    "---\n",
    "\n",
    "## Visual Prompts\n",
    "Each scene has visual_prompts (array of objects):\n",
    "- stage_type: \"base\", \"lighting\", or \"details\"\n",
    "- prompt: description text\n",
    "Omit unused stages.\n",
    "\n",
    "---\n",
    "\n",
    "## Animation\n",
    "Each scene must include:\n",
    "- animation_type: \"Ken Burns\", \"Parallax\", \"Cinemagraph\", \"Dolly Zoom\", or \"Static\"\n",
    "- ffmpeg_command: string showing how to apply effect\n",
    "\n",
    "Example:\n",
    "```json\n",
    "{{\n",
    "  \"animation_type\": \"Ken Burns\",\n",
    "  \"ffmpeg_command\": \"-vf zoompan=d=250:fps=25,scale=1080:1920\"\n",
    "}}\n",
    "Story:\n",
    "{story_text}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e074ac51-c8dc-4dc5-9c5e-69b73fa9a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "template = ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a47b86e-cc11-4bf1-93fa-48052323dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Literal\n",
    "\n",
    "\n",
    "class GeographicLocation(BaseModel):\n",
    "    country: Optional[str] = None\n",
    "    specific_location: Optional[str] = None\n",
    "\n",
    "\n",
    "class TimePeriod(BaseModel):\n",
    "    era: Optional[str] = None\n",
    "    time_of_day: Optional[str] = None\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    condition: Optional[str] = None\n",
    "    details: Optional[str] = None\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    role: Literal[\"hero\", \"narrator\", \"bystander\", \"antagonist\", \"supporting\"]\n",
    "    visual_features: Optional[str] = None\n",
    "    psychological_features: Optional[str] = None\n",
    "\n",
    "\n",
    "class Profile(BaseModel):\n",
    "    geographic_location: GeographicLocation\n",
    "    time_period: TimePeriod\n",
    "    weather: Weather\n",
    "    ethnicity: Optional[str] = None\n",
    "    mood: Optional[str] = None\n",
    "    characters: List[Character] = []\n",
    "\n",
    "\n",
    "class VisualPromptStage(BaseModel):\n",
    "    stage_type: Literal[\"base\", \"lighting\", \"details\"]\n",
    "    prompt: str\n",
    "\n",
    "\n",
    "class Style(BaseModel):\n",
    "    style_description: str\n",
    "\n",
    "\n",
    "class Animation(BaseModel):\n",
    "    animation_type: Literal[\"Ken Burns\", \"Parallax\", \"Cinemagraph\", \"Dolly Zoom\", \"Static\"]\n",
    "    ffmpeg_command: str = Field(..., description=\"ffmpeg command to apply this animation\")\n",
    "\n",
    "\n",
    "class Subtitle(BaseModel):\n",
    "    index: int = Field(..., description=\"Sequential subtitle index (starts at 1 for each scene)\")\n",
    "    start_time: str = Field(..., description=\"Start time in HH:MM:SS,mmm\")\n",
    "    end_time: str = Field(..., description=\"End time in HH:MM:SS,mmm\")\n",
    "    text: str = Field(..., description=\"Subtitle text, ≤42 chars per line\")\n",
    "\n",
    "\n",
    "class Scene(BaseModel):\n",
    "    scene_index: int\n",
    "    narration_text: str\n",
    "    subtitle_text: str\n",
    "    visual_prompts: List[VisualPromptStage]\n",
    "    background_music: str\n",
    "    animation: Animation\n",
    "    duration_sec: int\n",
    "    strength_from_previous: float = Field(..., ge=0.0, le=1.0, description=\"Scene transition blending strength\")\n",
    "    subtitles: List[Subtitle] = Field(..., description=\"Per-scene subtitles in SRT format\")\n",
    "\n",
    "\n",
    "class StoryBoard(BaseModel):\n",
    "    profile: Profile\n",
    "    style: Style\n",
    "    scenes: List[Scene]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abba26b-c33d-4cbe-bfc5-f906a74d6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    openai_api_key=openai_key,\n",
    ")\n",
    "\n",
    "llm = llm.with_structured_output(StoryBoard)  # Enable structured output for Scenes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7356eff-9357-4b79-b46d-402344e8ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e06a2cc-8986-49f9-81a2-2d3ab524cd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"story_text\": \"\\n\\n\".join(parts)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddc21bff-2e5f-4648-925d-8ce1408192a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: They are still there\\n\\nThe Arrival\\nIt was past 8:00 PM when Riya, Kabir, and Mehul entered the silent city of Bansipur.\\nA faint mist curled along the cracked roads, the streetlamps flickering as if unsure they wanted to stay lit.\\nThey had been driving for hours, lost after taking a wrong turn from the highway. Fuel gauge—dangerously low.\\nBansipur looked deserted, except for one building at the end of the main road:\\na bright, glowing sign that read “Mehta Super Mart – Always Open.”\\nRiya gave a nervous laugh.\\n“Creepy or not, we need snacks. And water. And… maybe a map.”\\nThey parked, the sound of their car engine echoing too loudly in the empty street.\\nThe sliding doors of the supermarket opened with a slow hiss, though no one stood behind the counter.\\nInside, the air was too cold for summer.\\nThe lights buzzed overhead, but the aisles were perfectly stocked—cereal boxes lined like soldiers, canned goods gleaming, fruits unnaturally shiny.\\nMehul called out, “Hello? Anyone here?”\\nOnly the sound of the automatic doors sighing shut behind them replied.\\n\\n\\nThe Descent\\nThey walked toward the back, looking for a cashier, when Kabir noticed a sign:\\n“More items downstairs →”\\nA narrow staircase led downward, lit by a single dangling bulb.\\n“Maybe the office is down there?” Riya suggested.\\nThe steps creaked under their feet. The air smelled of something damp and metallic.\\nThey reached the bottom—\\n—only to find another sign:\\n“More items downstairs →”\\nAnother staircase. Same dim bulb. Same creaking steps.\\n“Wait,” Mehul said, frowning, “We just… came down. How is there another one?”\\nThey climbed back up—\\n—but when they reached the “top,” it wasn’t the supermarket floor.\\nIt was another identical staircase… leading further down.\\nThe walls seemed closer. The air, heavier.\\nThey tried running up, running down, skipping steps, even counting—but the count never ended.\\nEvery landing led to the same staircase, the same buzzing bulb, the same damp smell.\\n\\n\\nThe Last Step\\nHours—or maybe minutes—passed.\\nTheir phones had no signal. Batteries drained faster than they should.\\nRiya’s water bottle slipped from her hand and rolled down… endlessly. They never heard it hit the bottom.\\nKabir began muttering, “We’re not supposed to be here… We weren’t supposed to see this.”\\nThen they noticed something new—\\nOn the wall, near the bulb, a smear. Dark red.\\nThe smear grew fresher, dripping.\\nFrom above, faint footsteps echoed—slow, deliberate.\\nBut when they looked up, the staircase was empty.\\nThe lights began to flicker, and in one brief flash, Riya saw them—\\nThree figures. Pale. Wide-eyed. Standing on the stairs just a few steps above.\\nThey looked exactly like Riya, Kabir, and Mehul—\\n—but their faces were twisted, rotting, their eyes black pits.\\nThe next flicker of light went out completely.\\nIn the darkness, the footsteps came closer.\\nThe last thing anyone heard was the supermarket doors hissing open upstairs…\\n…with no one coming out.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d21a1a52-cc08-4d4f-9d87-a7cfb890cbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f8c07d-549f-4eaa-8c25-3ac30cffef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile(geographic_location=GeographicLocation(country='India', specific_location='Bansipur'), time_period=TimePeriod(era='Modern', time_of_day='Night'), weather=Weather(condition='Misty', details='Faint mist curling along roads'), ethnicity='South Asian', mood='Eerie, suspenseful', characters=[Character(name='Riya', role='hero', visual_features='Young woman, nervous expression', psychological_features='Anxious but determined'), Character(name='Kabir', role='supporting', visual_features='Young man, thoughtful demeanor', psychological_features='Cautious and observant'), Character(name='Mehul', role='supporting', visual_features='Young man, curious eyes', psychological_features='Inquisitive and brave')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a0f18b3-ea32-4e54-99a8-68a777822ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Style(style_description=\"Cinematic style with a handheld feel, shot on a digital camera with a 35mm lens. Lighting is dim and moody, with a cool color palette. The tone is suspenseful, reminiscent of Hitchcock's thrillers, with a touch of supernatural horror.\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42cca304-20d6-4ea5-8aca-9b673c4117e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Scene(scene_index=1, narration_text='It was past 8:00 PM when Riya, Kabir, and Mehul entered the silent city of Bansipur. A faint mist curled along the cracked roads, the streetlamps flickering as if unsure they wanted to stay lit.', subtitle_text='The Arrival', visual_prompts=[VisualPromptStage(stage_type='base', prompt='A car driving into a misty, deserted city at night.'), VisualPromptStage(stage_type='lighting', prompt='Streetlamps flickering, casting eerie shadows.')], background_music='Low, suspenseful strings with a hint of wind howling.', animation=Animation(animation_type='Ken Burns', ffmpeg_command='-vf zoompan=d=250:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=0.5, subtitles=[Subtitle(index=1, start_time='00:00:01,000', end_time='00:00:05,000', text='It was past 8:00 PM when Riya, Kabir, and Mehul entered the silent city of Bansipur.'), Subtitle(index=2, start_time='00:00:05,500', end_time='00:00:10,000', text='A faint mist curled along the cracked roads, the streetlamps flickering as if unsure they wanted to stay lit.')]),\n",
       " Scene(scene_index=2, narration_text='They had been driving for hours, lost after taking a wrong turn from the highway. Fuel gauge—dangerously low.', subtitle_text='Lost and Low on Fuel', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Interior of a car, dashboard showing low fuel.'), VisualPromptStage(stage_type='details', prompt='Riya looking worried, checking the map.')], background_music='Tense piano notes with a ticking clock sound.', animation=Animation(animation_type='Static', ffmpeg_command='-vf scale=1080:1920'), duration_sec=8, strength_from_previous=0.6, subtitles=[Subtitle(index=1, start_time='00:00:11,000', end_time='00:00:14,000', text='They had been driving for hours, lost after taking a wrong turn from the highway.'), Subtitle(index=2, start_time='00:00:14,500', end_time='00:00:18,000', text='Fuel gauge—dangerously low.')]),\n",
       " Scene(scene_index=3, narration_text='Bansipur looked deserted, except for one building at the end of the main road: a bright, glowing sign that read “Mehta Super Mart – Always Open.” Riya gave a nervous laugh.', subtitle_text='A Beacon in the Deserted City', visual_prompts=[VisualPromptStage(stage_type='base', prompt='A glowing supermarket sign in the distance.'), VisualPromptStage(stage_type='lighting', prompt='Neon lights casting a surreal glow.')], background_music='Ambient synths with a distant hum.', animation=Animation(animation_type='Parallax', ffmpeg_command='-vf parallax=1.5:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=0.7, subtitles=[Subtitle(index=1, start_time='00:00:19,000', end_time='00:00:23,000', text='Bansipur looked deserted, except for one building at the end of the main road: a bright, glowing sign that read “Mehta Super Mart – Always Open.”'), Subtitle(index=2, start_time='00:00:23,500', end_time='00:00:25,000', text='Riya gave a nervous laugh.')]),\n",
       " Scene(scene_index=4, narration_text='“Creepy or not, we need snacks. And water. And… maybe a map.” They parked, the sound of their car engine echoing too loudly in the empty street.', subtitle_text='Necessities First', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Riya, Kabir, and Mehul getting out of the car.'), VisualPromptStage(stage_type='details', prompt='Empty street with their footsteps echoing.')], background_music='Echoing footsteps with a distant car engine hum.', animation=Animation(animation_type='Static', ffmpeg_command='-vf scale=1080:1920'), duration_sec=8, strength_from_previous=0.8, subtitles=[Subtitle(index=1, start_time='00:00:26,000', end_time='00:00:29,000', text='“Creepy or not, we need snacks. And water. And… maybe a map.”'), Subtitle(index=2, start_time='00:00:29,500', end_time='00:00:32,000', text='They parked, the sound of their car engine echoing too loudly in the empty street.')]),\n",
       " Scene(scene_index=5, narration_text='The sliding doors of the supermarket opened with a slow hiss, though no one stood behind the counter. Inside, the air was too cold for summer.', subtitle_text='An Unsettling Welcome', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Supermarket entrance with sliding doors opening.'), VisualPromptStage(stage_type='lighting', prompt='Cold, fluorescent lighting inside.')], background_music='Soft, eerie synths with a low hum.', animation=Animation(animation_type='Cinemagraph', ffmpeg_command='-vf loop=1:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=0.9, subtitles=[Subtitle(index=1, start_time='00:00:33,000', end_time='00:00:36,000', text='The sliding doors of the supermarket opened with a slow hiss, though no one stood behind the counter.'), Subtitle(index=2, start_time='00:00:36,500', end_time='00:00:39,000', text='Inside, the air was too cold for summer.')]),\n",
       " Scene(scene_index=6, narration_text='The lights buzzed overhead, but the aisles were perfectly stocked—cereal boxes lined like soldiers, canned goods gleaming, fruits unnaturally shiny.', subtitle_text='Too Perfect to be Real', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Aisles of a supermarket, perfectly stocked.'), VisualPromptStage(stage_type='details', prompt='Cereal boxes lined neatly, fruits shining.')], background_music='Buzzing fluorescent lights with a faint melody.', animation=Animation(animation_type='Ken Burns', ffmpeg_command='-vf zoompan=d=250:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:00:40,000', end_time='00:00:44,000', text='The lights buzzed overhead, but the aisles were perfectly stocked—cereal boxes lined like soldiers, canned goods gleaming, fruits unnaturally shiny.')]),\n",
       " Scene(scene_index=7, narration_text='Mehul called out, “Hello? Anyone here?” Only the sound of the automatic doors sighing shut behind them replied.', subtitle_text='Echoes of Silence', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Mehul standing in an empty aisle, calling out.'), VisualPromptStage(stage_type='details', prompt='Automatic doors closing with a soft hiss.')], background_music='Silence with a distant echo.', animation=Animation(animation_type='Static', ffmpeg_command='-vf scale=1080:1920'), duration_sec=8, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:00:45,000', end_time='00:00:47,000', text='Mehul called out, “Hello? Anyone here?”'), Subtitle(index=2, start_time='00:00:47,500', end_time='00:00:49,000', text='Only the sound of the automatic doors sighing shut behind them replied.')]),\n",
       " Scene(scene_index=8, narration_text='They walked toward the back, looking for a cashier, when Kabir noticed a sign: “More items downstairs →” A narrow staircase led downward, lit by a single dangling bulb.', subtitle_text='The Descent Begins', visual_prompts=[VisualPromptStage(stage_type='base', prompt='A narrow staircase leading downwards.'), VisualPromptStage(stage_type='lighting', prompt='Dim bulb casting shadows on the stairs.')], background_music='Low, ominous tones with a faint heartbeat.', animation=Animation(animation_type='Parallax', ffmpeg_command='-vf parallax=1.5:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=0.7, subtitles=[Subtitle(index=1, start_time='00:00:50,000', end_time='00:00:53,000', text='They walked toward the back, looking for a cashier, when Kabir noticed a sign: “More items downstairs →”'), Subtitle(index=2, start_time='00:00:53,500', end_time='00:00:56,000', text='A narrow staircase led downward, lit by a single dangling bulb.')]),\n",
       " Scene(scene_index=9, narration_text='“Maybe the office is down there?” Riya suggested. The steps creaked under their feet. The air smelled of something damp and metallic.', subtitle_text='A Step into the Unknown', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Riya leading the way down the stairs.'), VisualPromptStage(stage_type='details', prompt='Creaking steps and damp, metallic smell.')], background_music='Creaking wood with a distant metallic clang.', animation=Animation(animation_type='Cinemagraph', ffmpeg_command='-vf loop=1:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=0.8, subtitles=[Subtitle(index=1, start_time='00:00:57,000', end_time='00:00:59,000', text='“Maybe the office is down there?” Riya suggested.'), Subtitle(index=2, start_time='00:00:59,500', end_time='00:01:02,000', text='The steps creaked under their feet. The air smelled of something damp and metallic.')]),\n",
       " Scene(scene_index=10, narration_text='They reached the bottom— —only to find another sign: “More items downstairs →” Another staircase. Same dim bulb. Same creaking steps.', subtitle_text='An Endless Descent', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Another identical staircase at the bottom.'), VisualPromptStage(stage_type='details', prompt='Dim bulb and creaking steps repeating.')], background_music='Repetitive, eerie tones with a low drone.', animation=Animation(animation_type='Ken Burns', ffmpeg_command='-vf zoompan=d=250:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=0.9, subtitles=[Subtitle(index=1, start_time='00:01:03,000', end_time='00:01:05,000', text='They reached the bottom—'), Subtitle(index=2, start_time='00:01:05,500', end_time='00:01:08,000', text='—only to find another sign: “More items downstairs →”'), Subtitle(index=3, start_time='00:01:08,500', end_time='00:01:10,000', text='Another staircase. Same dim bulb. Same creaking steps.')]),\n",
       " Scene(scene_index=11, narration_text='“Wait,” Mehul said, frowning, “We just… came down. How is there another one?” They climbed back up— —but when they reached the “top,” it wasn’t the supermarket floor.', subtitle_text='A Looping Nightmare', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Mehul looking confused at the repeating staircase.'), VisualPromptStage(stage_type='details', prompt='Staircase looping back on itself.')], background_music='Confused whispers with a looping melody.', animation=Animation(animation_type='Parallax', ffmpeg_command='-vf parallax=1.5:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:11,000', end_time='00:01:13,000', text='“Wait,” Mehul said, frowning, “We just… came down. How is there another one?”'), Subtitle(index=2, start_time='00:01:13,500', end_time='00:01:15,000', text='They climbed back up—'), Subtitle(index=3, start_time='00:01:15,500', end_time='00:01:17,000', text='—but when they reached the “top,” it wasn’t the supermarket floor.')]),\n",
       " Scene(scene_index=12, narration_text='It was another identical staircase… leading further down. The walls seemed closer. The air, heavier.', subtitle_text='Deeper into the Abyss', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Staircase leading further down, walls closing in.'), VisualPromptStage(stage_type='lighting', prompt='Heavy, oppressive atmosphere.')], background_music='Deep, resonant tones with a heavy bass.', animation=Animation(animation_type='Cinemagraph', ffmpeg_command='-vf loop=1:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:18,000', end_time='00:01:20,000', text='It was another identical staircase… leading further down.'), Subtitle(index=2, start_time='00:01:20,500', end_time='00:01:22,000', text='The walls seemed closer. The air, heavier.')]),\n",
       " Scene(scene_index=13, narration_text='They tried running up, running down, skipping steps, even counting—but the count never ended. Every landing led to the same staircase, the same buzzing bulb, the same damp smell.', subtitle_text='Trapped in Infinity', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Riya, Kabir, and Mehul running up and down the stairs.'), VisualPromptStage(stage_type='details', prompt='Buzzing bulb and damp smell repeating.')], background_music='Fast-paced, frantic strings with a repetitive beat.', animation=Animation(animation_type='Ken Burns', ffmpeg_command='-vf zoompan=d=250:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:23,000', end_time='00:01:25,000', text='They tried running up, running down, skipping steps, even counting—but the count never ended.'), Subtitle(index=2, start_time='00:01:25,500', end_time='00:01:27,000', text='Every landing led to the same staircase, the same buzzing bulb, the same damp smell.')]),\n",
       " Scene(scene_index=14, narration_text='Hours—or maybe minutes—passed. Their phones had no signal. Batteries drained faster than they should.', subtitle_text='Time Slips Away', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Close-up of phones with no signal, batteries draining.'), VisualPromptStage(stage_type='details', prompt='Riya looking at her watch, confused.')], background_music='Slow, ticking clock with a fading melody.', animation=Animation(animation_type='Static', ffmpeg_command='-vf scale=1080:1920'), duration_sec=8, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:28,000', end_time='00:01:30,000', text='Hours—or maybe minutes—passed.'), Subtitle(index=2, start_time='00:01:30,500', end_time='00:01:32,000', text='Their phones had no signal. Batteries drained faster than they should.')]),\n",
       " Scene(scene_index=15, narration_text='Riya’s water bottle slipped from her hand and rolled down… endlessly. They never heard it hit the bottom.', subtitle_text='Endless Descent', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Water bottle rolling down the stairs, disappearing into darkness.'), VisualPromptStage(stage_type='details', prompt='Riya watching it roll, eyes wide.')], background_music='Echoing roll with a distant, fading sound.', animation=Animation(animation_type='Cinemagraph', ffmpeg_command='-vf loop=1:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:33,000', end_time='00:01:35,000', text='Riya’s water bottle slipped from her hand and rolled down… endlessly.'), Subtitle(index=2, start_time='00:01:35,500', end_time='00:01:37,000', text='They never heard it hit the bottom.')]),\n",
       " Scene(scene_index=16, narration_text='Kabir began muttering, “We’re not supposed to be here… We weren’t supposed to see this.” Then they noticed something new— On the wall, near the bulb, a smear. Dark red.', subtitle_text='A Sinister Discovery', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Kabir muttering to himself, looking distressed.'), VisualPromptStage(stage_type='details', prompt='Dark red smear on the wall near the bulb.')], background_music='Low, ominous hum with a rising tension.', animation=Animation(animation_type='Ken Burns', ffmpeg_command='-vf zoompan=d=250:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:38,000', end_time='00:01:40,000', text='Kabir began muttering, “We’re not supposed to be here… We weren’t supposed to see this.”'), Subtitle(index=2, start_time='00:01:40,500', end_time='00:01:42,000', text='Then they noticed something new—'), Subtitle(index=3, start_time='00:01:42,500', end_time='00:01:44,000', text='On the wall, near the bulb, a smear. Dark red.')]),\n",
       " Scene(scene_index=17, narration_text='The smear grew fresher, dripping. From above, faint footsteps echoed—slow, deliberate.', subtitle_text='The Presence Above', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Dark red smear dripping down the wall.'), VisualPromptStage(stage_type='details', prompt='Faint footsteps echoing from above.')], background_music='Slow, deliberate footsteps with a dripping sound.', animation=Animation(animation_type='Parallax', ffmpeg_command='-vf parallax=1.5:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:45,000', end_time='00:01:47,000', text='The smear grew fresher, dripping.'), Subtitle(index=2, start_time='00:01:47,500', end_time='00:01:49,000', text='From above, faint footsteps echoed—slow, deliberate.')]),\n",
       " Scene(scene_index=18, narration_text='But when they looked up, the staircase was empty. The lights began to flicker, and in one brief flash, Riya saw them— Three figures. Pale. Wide-eyed. Standing on the stairs just a few steps above.', subtitle_text='A Glimpse of Horror', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Riya looking up at the empty staircase.'), VisualPromptStage(stage_type='details', prompt='Flickering lights revealing pale figures.')], background_music='Flickering lights with a sudden, sharp note.', animation=Animation(animation_type='Cinemagraph', ffmpeg_command='-vf loop=1:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:50,000', end_time='00:01:52,000', text='But when they looked up, the staircase was empty.'), Subtitle(index=2, start_time='00:01:52,500', end_time='00:01:54,000', text='The lights began to flicker, and in one brief flash, Riya saw them—'), Subtitle(index=3, start_time='00:01:54,500', end_time='00:01:56,000', text='Three figures. Pale. Wide-eyed. Standing on the stairs just a few steps above.')]),\n",
       " Scene(scene_index=19, narration_text='They looked exactly like Riya, Kabir, and Mehul— —but their faces were twisted, rotting, their eyes black pits.', subtitle_text='Reflections of Fear', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Figures resembling Riya, Kabir, and Mehul, but distorted.'), VisualPromptStage(stage_type='details', prompt='Twisted faces with black pit eyes.')], background_music='Distorted, eerie tones with a low rumble.', animation=Animation(animation_type='Ken Burns', ffmpeg_command='-vf zoompan=d=250:fps=25,scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:01:57,000', end_time='00:01:59,000', text='They looked exactly like Riya, Kabir, and Mehul—'), Subtitle(index=2, start_time='00:01:59,500', end_time='00:02:01,000', text='—but their faces were twisted, rotting, their eyes black pits.')]),\n",
       " Scene(scene_index=20, narration_text='The next flicker of light went out completely. In the darkness, the footsteps came closer. The last thing anyone heard was the supermarket doors hissing open upstairs… …with no one coming out.', subtitle_text='The Final Silence', visual_prompts=[VisualPromptStage(stage_type='base', prompt='Complete darkness with footsteps approaching.'), VisualPromptStage(stage_type='details', prompt='Supermarket doors hissing open with no one visible.')], background_music='Complete silence with a distant, echoing hiss.', animation=Animation(animation_type='Static', ffmpeg_command='-vf scale=1080:1920'), duration_sec=10, strength_from_previous=1.0, subtitles=[Subtitle(index=1, start_time='00:02:02,000', end_time='00:02:04,000', text='The next flicker of light went out completely.'), Subtitle(index=2, start_time='00:02:04,500', end_time='00:02:06,000', text='In the darkness, the footsteps came closer.'), Subtitle(index=3, start_time='00:02:06,500', end_time='00:02:08,000', text='The last thing anyone heard was the supermarket doors hissing open upstairs…'), Subtitle(index=4, start_time='00:02:08,500', end_time='00:02:10,000', text='…with no one coming out.')])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f7fa9-172d-4dae-93e8-681224db195a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scene Profile (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e1cdce6-c6df-4f8e-9fa0-9eb72d9475f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def to_profile_tab(profile: Profile) -> str:\n",
    "    rows = [\n",
    "        [\"Geographic Location\", f\"{profile.geographic_location.country or ''}, {profile.geographic_location.specific_location or ''}\"],\n",
    "        [\"Time Period\", f\"Era: {profile.time_period.era or ''}, Time: {profile.time_period.time_of_day or ''}\"],\n",
    "        [\"Weather\", f\"{profile.weather.condition or ''} ({profile.weather.details or ''})\"],\n",
    "        [\"Ethnicity\", profile.ethnicity or \"\"],\n",
    "        [\"Mood\", profile.mood or \"\"],\n",
    "    ]\n",
    "    \n",
    "    # Add characters as a sub-table\n",
    "    char_rows = []\n",
    "    for c in profile.characters:\n",
    "        char_rows.append([\n",
    "            c.name,\n",
    "            c.role,\n",
    "            c.visual_features or \"\",\n",
    "            c.psychological_features or \"\"\n",
    "        ])\n",
    "    \n",
    "    table_str = tabulate(rows, headers=[\"Attribute\", \"Value\"], tablefmt=\"grid\")\n",
    "    \n",
    "    if char_rows:\n",
    "        char_table = tabulate(\n",
    "            char_rows, \n",
    "            headers=[\"Name\", \"Role\", \"Visual Features\", \"Psychological Features\"], \n",
    "            tablefmt=\"grid\"\n",
    "        )\n",
    "        table_str += \"\\n\\nCharacters:\\n\" + char_table\n",
    "    \n",
    "    return table_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cdd5ab20-a0a8-4dbf-9713-21f869fb5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_str = to_profile_tab(result.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d12d0c56-b46d-4171-9a70-32a6cbae803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------------------------+\n",
      "| Attribute           | Value                                  |\n",
      "+=====================+========================================+\n",
      "| Geographic Location | India, Bansipur                        |\n",
      "+---------------------+----------------------------------------+\n",
      "| Time Period         | Era: modern, Time: night               |\n",
      "+---------------------+----------------------------------------+\n",
      "| Weather             | misty (faint mist curling along roads) |\n",
      "+---------------------+----------------------------------------+\n",
      "| Ethnicity           | South Asian                            |\n",
      "+---------------------+----------------------------------------+\n",
      "| Mood                | eerie, suspenseful                     |\n",
      "+---------------------+----------------------------------------+\n",
      "\n",
      "Characters:\n",
      "+--------+------------+---------------------------------------+--------------------------+\n",
      "| Name   | Role       | Visual Features                       | Psychological Features   |\n",
      "+========+============+=======================================+==========================+\n",
      "| Riya   | hero       | young woman, long hair, casual attire | nervous, determined      |\n",
      "+--------+------------+---------------------------------------+--------------------------+\n",
      "| Kabir  | supporting | young man, short hair, casual attire  | curious, cautious        |\n",
      "+--------+------------+---------------------------------------+--------------------------+\n",
      "| Mehul  | supporting | young man, glasses, casual attire     | skeptical, observant     |\n",
      "+--------+------------+---------------------------------------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(profile_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c02943-36e2-444d-af22-b3e709f9f215",
   "metadata": {},
   "source": [
    "# Stage Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb7791c6-99a2-48ea-ba7c-8cb7affd5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from pathlib import Path\n",
    "\n",
    "id = str(uuid4())\n",
    "\n",
    "stage_dir = Path(os.getcwd()) / \"stage\" / id\n",
    "stage_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "517bd3cb-7342-450b-8e13-16fc4933f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = stage_dir / \"images\"\n",
    "raw_images_dir = images_dir / \"raw\"\n",
    "raw_images_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee51fd9d-b46e-4200-ab44-5bf01c4ab896",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_images_dir = images_dir / \"clean\"\n",
    "clean_images_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80cb8b67-50d0-41df-be40-e9075fddd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = stage_dir / \"audios\"\n",
    "audio_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bd2c98c-c5c8-4bd5-90e8-f128a7228b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = stage_dir / \"videos\"\n",
    "video_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f205e-9813-4070-98a9-f08a5d93b902",
   "metadata": {},
   "source": [
    "# Scene Temporary Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "abe2826a-0770-4c15-a547-c66af60ab2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_dict = result.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb8fa02b-3831-4c1f-8eb6-446d72f50290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(stage_dir / \"board.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    import json\n",
    "    json.dump(board_dict, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293da449-3053-4271-97c4-95b93bf5503c",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fb40a61-acad-4b9f-9ac8-a21e87246e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_index=1 narration_text='It was past 8:00 PM when Riya, Kabir, and Mehul entered the silent city of Bansipur. A faint mist curled along the cracked roads, the streetlamps flickering as if unsure they wanted to stay lit.' subtitle_text='The Arrival' visual_prompts=[VisualPromptStage(stage_type='base', prompt='A car driving into a misty, deserted city at night.'), VisualPromptStage(stage_type='lighting', prompt='Streetlamps flickering, casting eerie shadows.')] background_music='Low, suspenseful strings with a hint of wind howling.' animation=Animation(animation_type='Ken Burns', ffmpeg_command='-vf zoompan=d=250:fps=25,scale=1080:1920') duration_sec=10 strength_from_previous=0.5 subtitles=[Subtitle(index=1, start_time='00:00:01,000', end_time='00:00:05,000', text='It was past 8:00 PM when Riya, Kabir, and Mehul entered the silent city of Bansipur.'), Subtitle(index=2, start_time='00:00:05,500', end_time='00:00:10,000', text='A faint mist curled along the cracked roads, the streetlamps flickering as if unsure they wanted to stay lit.')]\n"
     ]
    }
   ],
   "source": [
    "current = result.scenes[0]\n",
    "print(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebf5d1b8-6aaa-4e37-9181-17411f024eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A car driving into a misty, deserted city at night.\n",
      "Streetlamps flickering, casting eerie shadows.Cinematic style with a handheld feel, shot on a digital camera with a 35mm lens. Lighting is dim and moody, with a cool color palette. The tone is suspenseful, reminiscent of Hitchcock's thrillers, with a touch of supernatural horror.\n"
     ]
    }
   ],
   "source": [
    "whole = '\\n'.join([ prompt.prompt for prompt in current.visual_prompts])\n",
    "whole = f\"{whole}{result.style.style_description}\"\n",
    "print(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73c15e79-80b0-4aa9-be2a-a862c567c9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cinematic style with a handheld feel, shot on a digital camera with a 35mm lens. Lighting is dim and moody, with a cool color palette. The tone is suspenseful, reminiscent of Hitchcock's thrillers, with a touch of supernatural horror.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.style.style_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "300f1285-b2f3-48ce-9871-3ad4f8a82661",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = \"http://3.143.254.8:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "250514e9-136d-451a-a01c-246dc71cb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "_NEGATIVE_PROMPT = \"\"\"\n",
    "    blurry, low quality, \n",
    "    low resolution, bad anatomy, bad hands, \n",
    "    missing fingers, extra digit, fewer digits, \n",
    "    cropped, worst quality, low quality, \n",
    "    normal quality, jpeg artifacts, signature, watermark, username, blurry,\n",
    "    cartoon, anime, illustration, comic, flat shading\n",
    "\"\"\"\n",
    "\n",
    "_DEFAULT_PARAMS = {\n",
    "    'guidance_scale': 7.5,\n",
    "    'strength': 0.45,\n",
    "    'orientation': 'portrait'\n",
    "}\n",
    "\n",
    "def call(text: str, image_path: str = None, params: dict = _DEFAULT_PARAMS):\n",
    "    path = \"/sm/txt2img\"\n",
    "    data = {\n",
    "        'prompt': text,\n",
    "        'negative_prompt': _NEGATIVE_PROMPT,\n",
    "        **params\n",
    "    }\n",
    "    if image_path:\n",
    "        path = \"/sm/img2img\"\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            data[\"image\"] = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    endpoint = f\"{api}{path}\"\n",
    "\n",
    "    response = requests.post(endpoint, \n",
    "                             data=json.dumps(data), \n",
    "                             headers={'Content-Type': 'application/json'},\n",
    "                             timeout=3000)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Request failed: {response.status_code} {response.text}\")\n",
    "    else:\n",
    "        img = json.loads(response.content.decode('utf-8'))\n",
    "        image_bytes = base64.b64decode(img['image_base64'])\n",
    "        return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0deb9a08-ff61-4652-bda8-8d107cc9059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def generate_raw_scene(idx: int, dir: str):\n",
    "    style = result.style\n",
    "    scene = result.scenes[idx]\n",
    "    images_dir = dir / str(idx)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    style_prompt = VisualPromptStage(stage_type=\"details\", prompt=style.style_description)\n",
    "    for i, prompt in enumerate([*scene.visual_prompts, style_prompt]):\n",
    "        logger.info(f\"Generating image for scene {idx}, prompt {i}: {prompt.prompt}\")\n",
    "        if i == 0:\n",
    "            img = call(text=prompt.prompt)\n",
    "        else:\n",
    "            prev_img_path = images_dir / f\"{i-1}.png\"\n",
    "            img = call(text=prompt.prompt, image_path=prev_img_path)\n",
    "        \n",
    "        output_path = images_dir / f\"{i}.png\"\n",
    "    \n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(img)\n",
    "        \n",
    "        if i == len(scene.visual_prompts) - 1:\n",
    "            output_path = images_dir / f\"final.png\"\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(img)\n",
    "\n",
    "    logger.info(f\"completed scene generation for scene - {idx}\")\n",
    "        \n",
    "def generate_raw_combined_scene(idx: int, dir: str):\n",
    "    style = result.style\n",
    "    scene = result.scenes[idx]\n",
    "    images_dir = dir / str(idx)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    whole = '\\n'.join([ prompt.prompt for prompt in scene.visual_prompts])\n",
    "    whole = f\"{whole}{style.style_description}\"\n",
    "    \n",
    "    img = call(text=whole)\n",
    "    output_path = images_dir / \"final.png\"\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(img)\n",
    "    \n",
    "    logger.info(f\"completed scene generation for scene - {idx}\")\n",
    "\n",
    "def generate_raw_combined_scene_with_past_reference(idx: int, dir: str):\n",
    "    style = result.style\n",
    "    scene = result.scenes[idx]\n",
    "    images_dir = dir / str(idx)\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    past_image = None\n",
    "    if idx > 0:\n",
    "        past_image_path = dir / str(idx - 1) / \"final.png\"\n",
    "        if past_image_path.exists():\n",
    "            past_image = past_image_path\n",
    "    \n",
    "    whole = '\\n'.join([ prompt.prompt for prompt in scene.visual_prompts])\n",
    "    whole = f\"{whole}{style.style_description}\"\n",
    "\n",
    "    if past_image:\n",
    "        img = call(text=whole, image_path=str(past_image), params = { **_DEFAULT_PARAMS, 'strength': scene.strength_from_previous })\n",
    "    else:\n",
    "        # If no past image, generate from scratch\n",
    "        img = call(text=whole)\n",
    "    output_path = images_dir / \"final.png\"\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(img)\n",
    "    \n",
    "    logger.info(f\"completed scene generation for scene - {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b6433ee-4a2c-4cf5-986e-9528290baf89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:completed scene generation for scene - 0\n",
      "INFO:__main__:completed scene generation for scene - 1\n",
      "INFO:__main__:completed scene generation for scene - 2\n",
      "INFO:__main__:completed scene generation for scene - 3\n",
      "INFO:__main__:completed scene generation for scene - 4\n",
      "INFO:__main__:completed scene generation for scene - 5\n",
      "INFO:__main__:completed scene generation for scene - 6\n",
      "INFO:__main__:completed scene generation for scene - 7\n",
      "INFO:__main__:completed scene generation for scene - 8\n",
      "INFO:__main__:completed scene generation for scene - 9\n",
      "INFO:__main__:completed scene generation for scene - 10\n",
      "INFO:__main__:completed scene generation for scene - 11\n",
      "INFO:__main__:completed scene generation for scene - 12\n",
      "INFO:__main__:completed scene generation for scene - 13\n",
      "INFO:__main__:completed scene generation for scene - 14\n",
      "INFO:__main__:completed scene generation for scene - 15\n",
      "INFO:__main__:completed scene generation for scene - 16\n",
      "INFO:__main__:completed scene generation for scene - 17\n",
      "INFO:__main__:completed scene generation for scene - 18\n",
      "INFO:__main__:completed scene generation for scene - 19\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for idx, scene in enumerate(result.scenes):\n",
    "    generate_raw_combined_scene(idx, raw_images_dir)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2f012-4fea-49e9-9624-0e698dda3c59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Image Upscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a91822e5-f315-4c6d-89de-a0d62639bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "\n",
    "def upscale(image_path: str = None, params: dict = {}):\n",
    "    path = \"/upscale/latent/v2\"\n",
    "    data = {\n",
    "        **params\n",
    "    }\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        data[\"image\"] = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    endpoint = f\"{api}{path}\"\n",
    "\n",
    "    response = requests.post(endpoint, \n",
    "                             data=json.dumps(data), \n",
    "                             headers={'Content-Type': 'application/json'},\n",
    "                             timeout=3000)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Request failed: {response.status_code} {response.text}\")\n",
    "    else:\n",
    "        img = json.loads(response.content.decode('utf-8'))\n",
    "        image_bytes = base64.b64decode(img['image_base64'])\n",
    "        return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1592b2b1-30e0-44cb-b0e7-4a938c1fd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def upscale_raw_scene(idx: int, input_dir: str, output_dir: str):\n",
    "    images_dir = output_dir\n",
    "    source_img_path = input_dir / f\"{idx}\" / \"final.png\"\n",
    "    image_bytes = upscale(source_img_path)\n",
    "    output_path = images_dir / f\"{idx}.png\"\n",
    "    \n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "90f4ce47-0f6a-43c5-a54e-7cb805b2ae78",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Request failed: 500 <!doctype html>\n<html lang=en>\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[134]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, scene \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(result.scenes):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mupscale_raw_scene\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_images_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_images_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     time.sleep(\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[133]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mupscale_raw_scene\u001b[39m\u001b[34m(idx, input_dir, output_dir)\u001b[39m\n\u001b[32m      4\u001b[39m images_dir = output_dir\n\u001b[32m      5\u001b[39m source_img_path = input_dir / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mfinal.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m image_bytes = \u001b[43mupscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_img_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m output_path = images_dir / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mupscale\u001b[39m\u001b[34m(image_path, params)\u001b[39m\n\u001b[32m     15\u001b[39m response = requests.post(endpoint, \n\u001b[32m     16\u001b[39m                          data=json.dumps(data), \n\u001b[32m     17\u001b[39m                          headers={\u001b[33m'\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m     18\u001b[39m                          timeout=\u001b[32m3000\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequest failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     23\u001b[39m     img = json.loads(response.content.decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mRuntimeError\u001b[39m: Request failed: 500 <!doctype html>\n<html lang=en>\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for idx, scene in enumerate(result.scenes):\n",
    "    upscale_raw_scene(idx, raw_images_dir, clean_images_dir)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43b65b-cba8-422d-bc20-b91760cd5a27",
   "metadata": {},
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b9753b0-9354-4222-bce9-7e3c59413268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_tts(text, filename):\n",
    "    \"\"\"Generate narration audio from text using OpenAI TTS.\"\"\"\n",
    "    speech = client.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"alloy\",\n",
    "        input=text\n",
    "    )\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(speech.read())\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b873e98-88b4-4612-b392-21803f550c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for idx, scene in enumerate(result.scenes):\n",
    "    output_path = audio_dir / f\"{idx}.mp3\"\n",
    "    generate_tts(scene.narration_text, output_path)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2bc71e-2123-4d93-8742-f862492e8e5a",
   "metadata": {},
   "source": [
    "# Generate Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2930abc7-a113-4d9b-a92a-6f35141aad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def create_video_with_ffmpeg(image_path, audio_path, animation_str, output_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "    if not os.path.exists(audio_path):\n",
    "        raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
    "    if animation_str:\n",
    "        # If an animation string is provided, use it in the ffmpeg command\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",\n",
    "            \"-loop\", \"1\",\n",
    "            \"-i\", image_path,\n",
    "            \"-i\", audio_path,\n",
    "            animation_str,\n",
    "            \"-c:v\", \"libx264\",\n",
    "            \"-tune\", \"stillimage\",\n",
    "            \"-c:a\", \"aac\",\n",
    "            \"-b:a\", \"192k\",\n",
    "            \"-pix_fmt\", \"yuv420p\",\n",
    "            \"-shortest\",\n",
    "            output_path\n",
    "        ]\n",
    "    else:\n",
    "        # Default command without animation\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",\n",
    "            \"-loop\", \"1\",\n",
    "            \"-i\", image_path,\n",
    "            \"-i\", audio_path,\n",
    "            \"-c:v\", \"libx264\",\n",
    "            \"-tune\", \"stillimage\",\n",
    "            \"-c:a\", \"aac\",\n",
    "            \"-b:a\", \"192k\",\n",
    "            \"-pix_fmt\", \"yuv420p\",\n",
    "            \"-shortest\",\n",
    "            output_path\n",
    "        ]\n",
    "    subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a3c10b1-d89e-4d69-9a40-1c712cd31c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, scene in enumerate(result.scenes):\n",
    "    image_path = images_dir / \"raw\" / str(idx) / \"final.png\"\n",
    "    audio_path = audio_dir / f\"{idx}.mp3\"\n",
    "    animation_str = scene.animation.ffmpeg_command if scene.animation else None\n",
    "    output_path = video_dir / f\"{idx}.mp4\"\n",
    "    create_video_with_ffmpeg(\n",
    "        str(image_path),\n",
    "        str(audio_path),\n",
    "        None,\n",
    "        str(output_path)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1868b-921d-454e-846a-f5eb1c4271e2",
   "metadata": {},
   "source": [
    "# Merge Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49ff26e5-95c5-464d-b9a4-6d3de53360a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/0.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/1.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/2.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/3.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/4.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/5.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/6.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/7.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/8.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/9.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/10.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/11.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/12.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/13.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/14.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/15.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/16.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/17.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/18.mp4'), WindowsPath('C:/Samriddha/opensource/examples/misc/projects/story-to-video/stage/37a7e017-e977-4eb0-8f97-9324c54049bc/videos/19.mp4')]\n"
     ]
    }
   ],
   "source": [
    "videos = [(video_dir / file) for file in sorted(os.listdir(video_dir)\n",
    "    , key=lambda x: int(x.split('.')[0]) if x.split('.')[0].isdigit() else 0)]\n",
    "\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78442e86-74b2-4a71-a80f-fe537786c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(stage_dir / \"scenes.txt\", \"w\") as f:\n",
    "    for video in videos:\n",
    "        # Convert path to forward slashes\n",
    "        path_str = video.as_posix()  # works if video is a Path object\n",
    "        f.write(f\"file '{path_str}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e141886-1052-40e1-b7f0-ed277300b67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video concatenation successful!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "try:\n",
    "    subprocess.run([\n",
    "        \"ffmpeg\",\n",
    "        \"-f\", \"concat\",\n",
    "        \"-safe\", \"0\",\n",
    "        \"-i\", str(stage_dir / \"scenes.txt\"),\n",
    "        \"-c:v\", \"libx264\",   # re-encode video\n",
    "        \"-crf\", \"23\",        # quality\n",
    "        \"-preset\", \"fast\",\n",
    "        \"-c:a\", \"aac\",       # audio codec\n",
    "        \"-b:a\", \"192k\",\n",
    "        str(stage_dir / \"story.mp4\")\n",
    "    ], check=True)\n",
    "    print(\"Video concatenation successful!\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"FFmpeg failed with exit code:\", e.returncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb729fc8-b1df-4727-92ea-e5f3f2cd204b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
