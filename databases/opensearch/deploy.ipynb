{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21be664d-7ffc-4725-bc92-a008c75549b3",
   "metadata": {},
   "source": [
    "# Deploy ML Model in OSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6b2131-6dc6-439b-84a1-6d2ad5785a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df216972-213f-449d-a023-cc6dbc1ae9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def make_requests(protocol, host, port, path, method, body=None, header=None):\n",
    "    try:\n",
    "        response = None\n",
    "        url = f\"{protocol}://{host}:{port}{path}\"\n",
    "        if method == 'GET':\n",
    "            response = requests.get(url, headers=header)\n",
    "        if method == 'POST':\n",
    "            response = requests.post(url, data=json.dumps(body), headers=header)\n",
    "        if method == 'PUT':\n",
    "            response = requests.put(url, data=json.dumps(body), headers=header)\n",
    "        if method == 'DELETE':\n",
    "            response = requests.delete(url, headers=header)\n",
    "        return response\n",
    "    except Exception as ex:\n",
    "        logger.error(f\"exception: {str(ex)}\")\n",
    "        raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da10702a-768a-4d93-8d7c-58b4316887ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = 'http'\n",
    "host = '3.93.0.242'\n",
    "port = 9200\n",
    "\n",
    "header = {\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278c8da-325a-41e3-8ecb-0bcbe61e4e01",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0659b78d-6df6-4632-8963-980cfa9d0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GROUP = \"search_v1_model_group\"\n",
    "MODEL_GROUP_DESCRIPTION = \"search_v1_model_group\"\n",
    "MODELS = [\n",
    "    {\n",
    "        \"MODEL_NAME\":\"huggingface/sentence-transformers/msmarco-distilbert-base-tas-b\",\n",
    "        \"MODEL_VERSION\":\"1.0.2\",\n",
    "        \"MODEL_FORMAT\":\"TORCH_SCRIPT\",\n",
    "        \"MODEL_TYPE\": \"dense\"\n",
    "    },\n",
    "    {\n",
    "        \"MODEL_NAME\":\"amazon/neural-sparse/opensearch-neural-sparse-encoding-v1\",\n",
    "        \"MODEL_VERSION\":\"1.0.1\",\n",
    "        \"MODEL_FORMAT\":\"TORCH_SCRIPT\",\n",
    "        \"MODEL_TYPE\": \"sparse\"\n",
    "    }\n",
    "]\n",
    "\n",
    "PIPELINE_NAME = \"default_ingestion_pipeline\"\n",
    "FIELD_MAP = {\n",
    "    \"huggingface/sentence-transformers/msmarco-distilbert-base-tas-b\": \"bert_embeddings\",\n",
    "    \"amazon/neural-sparse/opensearch-neural-sparse-encoding-v1\": \"oss_sparse_embeddings\"\n",
    "}\n",
    "\n",
    "SEARCH_PIPELINE_NAME='default_search_pipeline'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763783c-894e-4270-8b36-130b37a78f99",
   "metadata": {},
   "source": [
    "# Set Cluster Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136575e6-29e6-436a-8c9c-0fd42cfe3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:SET_CLUSTER_SETTINGS response: 200 body: {'acknowledged': True, 'persistent': {'plugins': {'ml_commons': {'only_run_on_ml_node': 'false', 'model_access_control_enabled': 'true', 'native_memory_threshold': '99'}}}, 'transient': {'plugins': {'ml_commons': {'model_access_control_enabled': 'true'}}}}\n"
     ]
    }
   ],
   "source": [
    "SET_CLUSTER_SETTINGS_PATH = \"/_cluster/settings\"\n",
    "SET_CLUSTER_SETTINGS_BODY = {\n",
    "  \"persistent\": {\n",
    "    \"plugins\": {\n",
    "      \"ml_commons\": {\n",
    "        \"only_run_on_ml_node\": \"false\",\n",
    "        \"model_access_control_enabled\": \"true\",\n",
    "        \"native_memory_threshold\": \"99\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"transient\": {\n",
    "    \"plugins.ml_commons.model_access_control_enabled\": \"true\"\n",
    "  }\n",
    "}\n",
    "\n",
    "response = make_requests(protocol, host, port, SET_CLUSTER_SETTINGS_PATH, 'PUT', body=SET_CLUSTER_SETTINGS_BODY, header=header)\n",
    "logger.info(f\"SET_CLUSTER_SETTINGS response: {response.status_code} body: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480c8d5-16de-40bd-8844-7608c23cc16a",
   "metadata": {},
   "source": [
    "# Register Model Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f77423-225d-4d6a-95cb-6f1c40bf8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:REGISTER_MODEL_GROUP response: 200 body: {'model_group_id': '0FlCF5EBMkhoZOcBzWSd', 'status': 'CREATED'}\n"
     ]
    }
   ],
   "source": [
    "REGISTER_MODEL_GROUP_PATH = \"/_plugins/_ml/model_groups/_register\"\n",
    "REGISTER_MODEL_GROUP_BODY = {\n",
    "  \"name\": MODEL_GROUP,\n",
    "  \"description\": MODEL_GROUP_DESCRIPTION\n",
    "}\n",
    "\n",
    "response = make_requests(protocol, host, port, REGISTER_MODEL_GROUP_PATH, 'POST', body=REGISTER_MODEL_GROUP_BODY, header=header)\n",
    "logger.info(f\"REGISTER_MODEL_GROUP response: {response.status_code} body: {response.json()}\")\n",
    "MODEL_GROUP_ID = response.json()['model_group_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5991e9d9-b75b-4f62-8708-50d6bc3e1955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TEST_MODEL_GROUP response: 200 body: {'took': 14, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 1, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': '.plugins-ml-model-group', '_id': '0FlCF5EBMkhoZOcBzWSd', '_version': 1, '_seq_no': 0, '_primary_term': 1, '_score': 1.0, '_source': {'created_time': 1722672139544, 'access': 'public', 'latest_version': 0, 'last_updated_time': 1722672139544, 'name': 'search_v1_model_group', 'description': 'search_v1_model_group'}}]}}\n"
     ]
    }
   ],
   "source": [
    "TEST_MODEL_GROUP_PATH = \"/_plugins/_ml/model_groups/_search\"\n",
    "TEST_MODEL_GROUP_BODY = {\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"_id\": MODEL_GROUP_ID\n",
    "    }\n",
    "  }\n",
    "}\n",
    "response = make_requests(protocol, host, port, TEST_MODEL_GROUP_PATH, 'POST', body=TEST_MODEL_GROUP_BODY, header=header)\n",
    "logger.info(f\"TEST_MODEL_GROUP response: {response.status_code} body: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97d781-7c98-43a0-a0ad-24cc8f3b21e0",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651f90b7-d7fb-423c-9d87-6fb761e5413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:REGISTER_MODEL response: 200 body: {'task_id': '0VlCF5EBMkhoZOcB92RQ', 'status': 'CREATED'}\n",
      "INFO:__main__:REGISTER_MODEL response: 200 body: {'task_id': '0llCF5EBMkhoZOcB-WRa', 'status': 'CREATED'}\n",
      "INFO:__main__:task ids ['0VlCF5EBMkhoZOcB92RQ', '0llCF5EBMkhoZOcB-WRa']\n"
     ]
    }
   ],
   "source": [
    "MODEL_TASK_IDS = []\n",
    "\n",
    "for m in MODELS:\n",
    "    REGISTER_MODEL_PATH = \"/_plugins/_ml/models/_register\"\n",
    "    REGISTER_MODEL_BODY = {\n",
    "      \"name\": m['MODEL_NAME'],\n",
    "      \"version\": m['MODEL_VERSION'],\n",
    "      \"model_group_id\": MODEL_GROUP_ID,\n",
    "      \"model_format\": m['MODEL_FORMAT']\n",
    "    }\n",
    "    \n",
    "    response = make_requests(protocol, host, port, REGISTER_MODEL_PATH, 'POST', body=REGISTER_MODEL_BODY, header=header)\n",
    "    logger.info(f\"REGISTER_MODEL response: {response.status_code} body: {response.json()}\")\n",
    "    MODEL_TASK_IDS.append(response.json()['task_id'])\n",
    "\n",
    "logger.info(f\"task ids {MODEL_TASK_IDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc4c184d-1fda-44b8-a192-c84cd0ac43d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TEST_MODEL response: 200 body: {'model_id': '1FlCF5EBMkhoZOcB-mQ9', 'task_type': 'REGISTER_MODEL', 'function_name': 'TEXT_EMBEDDING', 'state': 'COMPLETED', 'worker_node': ['bGY9drC5T6S-_poyFGzDQQ'], 'create_time': 1722672150244, 'last_update_time': 1722672198324, 'is_async': True}\n",
      "INFO:__main__:TEST_MODEL response: 200 body: {'model_id': '01lCF5EBMkhoZOcB-mQf', 'task_type': 'REGISTER_MODEL', 'function_name': 'SPARSE_ENCODING', 'state': 'COMPLETED', 'worker_node': ['bGY9drC5T6S-_poyFGzDQQ'], 'create_time': 1722672150873, 'last_update_time': 1722672222606, 'is_async': True}\n",
      "INFO:__main__:model ids ['1FlCF5EBMkhoZOcB-mQ9', '01lCF5EBMkhoZOcB-mQf']\n"
     ]
    }
   ],
   "source": [
    "MODEL_IDS = []\n",
    "MODEL_ID_MAP = {}\n",
    "for idx, t in enumerate(MODEL_TASK_IDS):\n",
    "    TEST_MODEL_PATH = f\"/_plugins/_ml/tasks/{t}\"\n",
    "    response = make_requests(protocol, host, port, TEST_MODEL_PATH, 'GET', header=header)\n",
    "    logger.info(f\"TEST_MODEL response: {response.status_code} body: {response.json()}\")\n",
    "    data = response.json()\n",
    "    if 'state' in data and data['state'] == 'COMPLETED':\n",
    "        MODEL_ID_MAP[data['model_id']] = MODELS[idx]['MODEL_NAME']\n",
    "        MODEL_IDS.append(data['model_id'])\n",
    "logger.info(f\"model ids {MODEL_IDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152b5ed-4c5d-44b6-ac17-415ea765f639",
   "metadata": {},
   "source": [
    "# Deploy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d984a30-c575-4358-9603-a03edbde86c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:DEPLOY_MODEL response: 200 body: {'task_id': '1VlFF5EBMkhoZOcBgmS6', 'task_type': 'DEPLOY_MODEL', 'status': 'CREATED'}\n",
      "INFO:__main__:DEPLOY_MODEL response: 200 body: {'task_id': '1llFF5EBMkhoZOcBhGTW', 'task_type': 'DEPLOY_MODEL', 'status': 'CREATED'}\n",
      "INFO:__main__:task ids ['1VlFF5EBMkhoZOcBgmS6', '1llFF5EBMkhoZOcBhGTW']\n"
     ]
    }
   ],
   "source": [
    "MODEL_DEPLOY_TASK_IDS = []\n",
    "\n",
    "for m in MODEL_IDS:\n",
    "    DEPLOY_MODEL_PATH = f\"/_plugins/_ml/models/{m}/_deploy\"\n",
    "    response = make_requests(protocol, host, port, DEPLOY_MODEL_PATH, 'POST', body={}, header=header)\n",
    "    logger.info(f\"DEPLOY_MODEL response: {response.status_code} body: {response.json()}\")\n",
    "    MODEL_DEPLOY_TASK_IDS.append(response.json()['task_id'])\n",
    "\n",
    "logger.info(f\"task ids {MODEL_DEPLOY_TASK_IDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c2f94d4-7d42-4a32-90bb-b55e778a358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TEST_MODEL response: 200 body: {'model_id': '1FlCF5EBMkhoZOcB-mQ9', 'task_type': 'DEPLOY_MODEL', 'function_name': 'TEXT_EMBEDDING', 'state': 'COMPLETED', 'worker_node': ['bGY9drC5T6S-_poyFGzDQQ'], 'create_time': 1722672317109, 'last_update_time': 1722672344443, 'is_async': True}\n",
      "INFO:__main__:task id 1VlFF5EBMkhoZOcBgmS6 is COMPLETED\n",
      "INFO:__main__:TEST_MODEL response: 200 body: {'model_id': '01lCF5EBMkhoZOcB-mQf', 'task_type': 'DEPLOY_MODEL', 'function_name': 'SPARSE_ENCODING', 'state': 'COMPLETED', 'worker_node': ['bGY9drC5T6S-_poyFGzDQQ'], 'create_time': 1722672317653, 'last_update_time': 1722672352803, 'is_async': True}\n",
      "INFO:__main__:task id 1llFF5EBMkhoZOcBhGTW is COMPLETED\n"
     ]
    }
   ],
   "source": [
    "for t in MODEL_DEPLOY_TASK_IDS:\n",
    "    TEST_MODEL_DEPLOY_TASK_PATH = f\"/_plugins/_ml/tasks/{t}\"\n",
    "    response = make_requests(protocol, host, port, TEST_MODEL_DEPLOY_TASK_PATH, 'GET', header=header)\n",
    "    logger.info(f\"TEST_MODEL response: {response.status_code} body: {response.json()}\")\n",
    "    data = response.json()\n",
    "    if 'state' in data and data['state'] == 'COMPLETED':\n",
    "        logger.info(f\"task id {t} is {data['state']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dec710-f648-43dd-822e-0fc5c1aa5859",
   "metadata": {},
   "source": [
    "# Deploy ReRanker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d17bca9-5707-4c70-8844-08c6b120e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSS_ENCODER_MODELS = [\n",
    "    {\n",
    "        \"MODEL_NAME\":\"huggingface/cross-encoders/ms-marco-MiniLM-L-6-v2\",\n",
    "        \"MODEL_VERSION\":\"1.0.2\",\n",
    "        \"MODEL_FORMAT\":\"TORCH_SCRIPT\",\n",
    "        \"MODEL_TYPE\": \"cross-encoder\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991e97a-c43f-4109-ab02-a213ad871869",
   "metadata": {},
   "source": [
    "# Register Cross Encoder Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453e6c0b-e899-4ad3-a3ed-1eeaf09d12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:REGISTER_MODEL response: 200 body: {'task_id': '11lGF5EBMkhoZOcBmmTL', 'status': 'CREATED'}\n",
      "INFO:__main__:task ids ['11lGF5EBMkhoZOcBmmTL']\n"
     ]
    }
   ],
   "source": [
    "CE_MODEL_TASK_IDS = []\n",
    "\n",
    "for m in CROSS_ENCODER_MODELS:\n",
    "    REGISTER_MODEL_PATH = \"/_plugins/_ml/models/_register\"\n",
    "    REGISTER_MODEL_BODY = {\n",
    "      \"name\": m['MODEL_NAME'],\n",
    "      \"version\": m['MODEL_VERSION'],\n",
    "      \"model_group_id\": MODEL_GROUP_ID,\n",
    "      \"model_format\": m['MODEL_FORMAT']\n",
    "    }\n",
    "    \n",
    "    response = make_requests(protocol, host, port, REGISTER_MODEL_PATH, 'POST', body=REGISTER_MODEL_BODY, header=header)\n",
    "    logger.info(f\"REGISTER_MODEL response: {response.status_code} body: {response.json()}\")\n",
    "    CE_MODEL_TASK_IDS.append(response.json()['task_id'])\n",
    "\n",
    "logger.info(f\"task ids {CE_MODEL_TASK_IDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95328c01-8ba5-449d-8222-5c8c894e1d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TEST_MODEL response: 200 body: {'model_id': '2FlGF5EBMkhoZOcBm2RT', 'task_type': 'REGISTER_MODEL', 'function_name': 'TEXT_SIMILARITY', 'state': 'COMPLETED', 'worker_node': ['bGY9drC5T6S-_poyFGzDQQ'], 'create_time': 1722672388810, 'last_update_time': 1722672398964, 'is_async': True}\n",
      "INFO:__main__:model ids ['2FlGF5EBMkhoZOcBm2RT']\n"
     ]
    }
   ],
   "source": [
    "CE_MODEL_IDS = []\n",
    "for idx, t in enumerate(CE_MODEL_TASK_IDS):\n",
    "    TEST_MODEL_PATH = f\"/_plugins/_ml/tasks/{t}\"\n",
    "    response = make_requests(protocol, host, port, TEST_MODEL_PATH, 'GET', header=header)\n",
    "    logger.info(f\"TEST_MODEL response: {response.status_code} body: {response.json()}\")\n",
    "    data = response.json()\n",
    "    if 'state' in data and data['state'] == 'COMPLETED':\n",
    "        CE_MODEL_IDS.append(data['model_id'])\n",
    "logger.info(f\"model ids {CE_MODEL_IDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f40b51-e3e2-486d-b202-3a7c34940968",
   "metadata": {},
   "source": [
    "# Deploy ReRanker Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b0462e9-6c13-454e-ae96-69c8c7820bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:DEPLOY_MODEL response: 200 body: {'task_id': '2VlGF5EBMkhoZOcB02SX', 'task_type': 'DEPLOY_MODEL', 'status': 'CREATED'}\n",
      "INFO:__main__:task ids ['2VlGF5EBMkhoZOcB02SX']\n"
     ]
    }
   ],
   "source": [
    "CE_MODEL_DEPLOY_TASK_IDS = []\n",
    "\n",
    "for m in CE_MODEL_IDS:\n",
    "    DEPLOY_MODEL_PATH = f\"/_plugins/_ml/models/{m}/_deploy\"\n",
    "    response = make_requests(protocol, host, port, DEPLOY_MODEL_PATH, 'POST', body={}, header=header)\n",
    "    logger.info(f\"DEPLOY_MODEL response: {response.status_code} body: {response.json()}\")\n",
    "    CE_MODEL_DEPLOY_TASK_IDS.append(response.json()['task_id'])\n",
    "\n",
    "logger.info(f\"task ids {CE_MODEL_DEPLOY_TASK_IDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8740d9d-47e3-492c-bf3a-2a51595dc77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TEST_MODEL response: 200 body: {'model_id': '2FlGF5EBMkhoZOcBm2RT', 'task_type': 'DEPLOY_MODEL', 'function_name': 'TEXT_SIMILARITY', 'state': 'COMPLETED', 'worker_node': ['bGY9drC5T6S-_poyFGzDQQ'], 'create_time': 1722672403350, 'last_update_time': 1722672405415, 'is_async': True}\n",
      "INFO:__main__:task id 2VlGF5EBMkhoZOcB02SX is COMPLETED\n"
     ]
    }
   ],
   "source": [
    "for t in CE_MODEL_DEPLOY_TASK_IDS:\n",
    "    TEST_MODEL_DEPLOY_TASK_PATH = f\"/_plugins/_ml/tasks/{t}\"\n",
    "    response = make_requests(protocol, host, port, TEST_MODEL_DEPLOY_TASK_PATH, 'GET', header=header)\n",
    "    logger.info(f\"TEST_MODEL response: {response.status_code} body: {response.json()}\")\n",
    "    data = response.json()\n",
    "    if 'state' in data and data['state'] == 'COMPLETED':\n",
    "        logger.info(f\"task id {t} is {data['state']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68318a44-7f4e-47c2-a4e8-242ad629be17",
   "metadata": {},
   "source": [
    "# Create Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60659a88-85a2-4da8-ae23-ed0cced8dcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:CREATE_PIPELINE response: 200 body: {'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "processors = []\n",
    "if len(MODEL_IDS) > 0:\n",
    "    for i, m in enumerate(MODEL_IDS):\n",
    "        if MODELS[i]['MODEL_TYPE'] == 'dense':\n",
    "            processors.append({\n",
    "                \"text_embedding\": {\n",
    "                    \"model_id\": m,\n",
    "                    \"field_map\": {\n",
    "                      \"text\": FIELD_MAP[MODEL_ID_MAP[m]]\n",
    "                    }\n",
    "              }\n",
    "            })\n",
    "        else:\n",
    "            processors.append({\n",
    "                \"sparse_encoding\": {\n",
    "                    \"model_id\": m,\n",
    "                    \"field_map\": {\n",
    "                      \"text\": FIELD_MAP[MODEL_ID_MAP[m]]\n",
    "                    }\n",
    "              }\n",
    "            })\n",
    "CREATE_PIPELINE_BODY = {\n",
    "    \"description\": PIPELINE_NAME,\n",
    "    \"processors\": processors\n",
    "}\n",
    "CREATE_PIPELINE_PATH = F\"/_ingest/pipeline/{PIPELINE_NAME}\"\n",
    "response = make_requests(protocol, host, port, CREATE_PIPELINE_PATH, 'PUT', body=CREATE_PIPELINE_BODY, header=header)\n",
    "logger.info(f\"CREATE_PIPELINE response: {response.status_code} body: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e109db3-ed8b-4ad5-ba41-f51e4264e4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:GET_PIPELINE response: 200 body: {'default_ingestion_pipeline': {'description': 'default_ingestion_pipeline', 'processors': [{'text_embedding': {'model_id': '1FlCF5EBMkhoZOcB-mQ9', 'field_map': {'text': 'bert_embeddings'}}}, {'sparse_encoding': {'model_id': '01lCF5EBMkhoZOcB-mQf', 'field_map': {'text': 'oss_sparse_embeddings'}}}]}}\n"
     ]
    }
   ],
   "source": [
    "GET_PIPELINE_PATH = F\"/_ingest/pipeline\"\n",
    "response = make_requests(protocol, host, port, GET_PIPELINE_PATH, 'GET', header=header)\n",
    "logger.info(f\"GET_PIPELINE response: {response.status_code} body: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f5007-8e06-4943-a058-f2a6a547b3ff",
   "metadata": {},
   "source": [
    "# Create Search Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b0cc2616-c1a4-47ff-a8c2-2f94ed460012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:CREATE_PIPELINE response: 200 body: {'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "response_processors = []\n",
    "if len(CE_MODEL_IDS) > 0:\n",
    "    for i, m in enumerate(CE_MODEL_IDS):\n",
    "        response_processors.append({\n",
    "                  \"rerank\": {\n",
    "                    \"ml_opensearch\": {\n",
    "                      \"model_id\": m\n",
    "                    },\n",
    "                    \"context\": {\n",
    "                      \"document_fields\": [\n",
    "                        \"text\"\n",
    "                      ]\n",
    "                    }\n",
    "                  }\n",
    "                })\n",
    "\n",
    "request_processor = {}\n",
    "if len(MODEL_IDS) > 0:\n",
    "    for i, m in enumerate(MODEL_IDS):\n",
    "        request_processor[FIELD_MAP[MODEL_ID_MAP[m]]]=m\n",
    "request_processors = [\n",
    "    {\n",
    "        'neural_query_enricher': {\n",
    "            'neural_field_default_id': request_processor\n",
    "        }\n",
    "    }\n",
    "]\n",
    "CREATE_SEARCH_PIPELINE_BODY = {\n",
    "    \"description\": SEARCH_PIPELINE_NAME,\n",
    "    \"request_processors\": request_processors,\n",
    "    \"response_processors\": response_processors\n",
    "}\n",
    "SEARCH_CREATE_PIPELINE_PATH = F\"/_search/pipeline/{SEARCH_PIPELINE_NAME}\"\n",
    "response = make_requests(protocol, host, port, SEARCH_CREATE_PIPELINE_PATH, 'PUT', body=CREATE_SEARCH_PIPELINE_BODY, header=header)\n",
    "logger.info(f\"CREATE_PIPELINE response: {response.status_code} body: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b48d5094-f3b6-4de6-8fc8-6caa3890df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:GET_PIPELINE response: 200 body: {'default_search_pipeline': {'description': 'default_search_pipeline', 'request_processors': [{'neural_query_enricher': {'neural_field_default_id': {'bert_embeddings': 'vERhsZABary_bsUAiOG2', 'oss_sparse_embeddings': 'vURhsZABary_bsUAieFJ'}}}], 'response_processors': [{'rerank': {'ml_opensearch': {'model_id': 'wURmsZABary_bsUAq-Hf'}, 'context': {'document_fields': ['text']}}}]}}\n"
     ]
    }
   ],
   "source": [
    "GET_PIPELINE_PATH = F\"/_search/pipeline\"\n",
    "response = make_requests(protocol, host, port, GET_PIPELINE_PATH, 'GET', header=header)\n",
    "logger.info(f\"GET_PIPELINE response: {response.status_code} body: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a21aea-8a46-4bf0-bba7-d48b11abdb19",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d391ee-e5c7-4cef-b75f-35d5e35571c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\"\"\"\n",
    "Delete ingest pipeline\n",
    "\"\"\"\n",
    "response = make_requests(protocol, host, port, f\"/_search/pipeline/{PIPELINE_NAME}\", 'DELETE', header=header)\n",
    "logger.info(f\"response: {response.status_code} body: {response.json()}\")\n",
    "\n",
    "\"\"\"\n",
    "Undeploy models\n",
    "\"\"\"\n",
    "for m in [*MODEL_IDS, *CE_MODEL_IDS]:\n",
    "    response = make_requests(protocol, host, port, f\"/_plugins/_ml/models/{m}/_undeploy\", 'POST', body={}, header=header)\n",
    "    logger.info(f\"response: {response.status_code} body: {response.json()}\")\n",
    "    time.sleep(120)\n",
    "    response = make_requests(protocol, host, port, f\"/_plugins/_ml/models/{m}\", 'DELETE', header=header)\n",
    "    logger.info(f\"response: {response.status_code} body: {response.json()}\")\n",
    "\n",
    "\"\"\"\n",
    "Delete model Group\n",
    "\"\"\"\n",
    "response = make_requests(protocol, host, port, f\"/_plugins/_ml/model_groups/{MODEL_GROUP_ID}\", 'DELETE', header=header)\n",
    "logger.info(f\"response: {response.status_code} body: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009c1f1-6caa-4fc4-9efe-67c631b222eb",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
